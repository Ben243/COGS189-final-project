{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne # package for reading edf data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  \n",
    "from sklearn.decomposition import PCA\n",
    "from data_tools import * # i made all t # i made all the functions into a python file\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = [4,8,12,30,45] #4 bands\n",
    "window_size = 2000 #Averaging band power of 2 sec\n",
    "step_size = 125 #1/8 second step\n",
    "sample_rate = 1000 #Each 0.125 sec update once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandNames = ['theta', 'alpha', 'beta', 'gamma']\n",
    "colNames = ['FP1', 'FP2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T3',\n",
    "       'C3', 'Cz', 'C4', 'T4', 'T5', 'P3', 'Pz', 'P4', 'T6', 'O1', 'O2']\n",
    "finalHeaderNames = []\n",
    "for header in colNames:\n",
    "    for bandName in bandNames:\n",
    "        finalHeaderNames.append(bandName + '_' + header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_Processing (clip):\n",
    "    meta = pd.DataFrame(data=[], columns=finalHeaderNames)\n",
    "    start = 0\n",
    "    while start + window_size < clip.shape[0]:\n",
    "        metaClip = pd.DataFrame(data=[], columns=finalHeaderNames)\n",
    "        meta_array = []\n",
    "        meta_data = [] #meta vector for analysis\n",
    "        for (columnName, columnData) in clip.iteritems():\n",
    "            X = columnData[start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "            Y = quick_bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "            meta_data.append(list(Y[0]))\n",
    "        metaClip = pd.DataFrame(data=[np.array(meta_data).flatten()], columns=finalHeaderNames)\n",
    "        meta = meta.append(metaClip)\n",
    "        start = start + step_size\n",
    "    return meta.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-28\\eeg\\sub-28_task-run2_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-28\\eeg\\sub-28_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-28\\eeg\\sub-28_task-run4_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-28\\eeg\\sub-28_task-run5_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-29\\eeg\\sub-29_task-run2_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-29\\eeg\\sub-29_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-29\\eeg\\sub-29_task-run4_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-29\\eeg\\sub-29_task-run5_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-30\\eeg\\sub-30_task-run2_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-30\\eeg\\sub-30_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-30\\eeg\\sub-30_task-run4_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-30\\eeg\\sub-30_task-run5_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-31\\eeg\\sub-31_task-run2_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-31\\eeg\\sub-31_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-31\\eeg\\sub-31_task-run4_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-31\\eeg\\sub-31_task-run5_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Processing completed!\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store our data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "train_pca = []\n",
    "test_pca = []\n",
    "\n",
    "test_set = np.random.choice(124, size=24, replace=False)\n",
    "\n",
    "# Going through all 124 trials\n",
    "for subject in range(1,32):\n",
    "    for trial in range(2,6):\n",
    "        df = get_recording_events(subject, trial)\n",
    "        labels = df.groupby('song_clip').head(1).TARGET.to_list() # Should be an array of 10 labels for each of the songs played in this trial\n",
    "        recordings = [df[df.song_clip==x].drop(columns=['song_clip','Number','TARGET','time']) for x in df.song_clip.unique()] \n",
    "        # Going through all 10 playings\n",
    "        for playing in range(0,10):\n",
    "            recording = recordings[playing]\n",
    "            if recording.shape[0] < 16000:\n",
    "                continue\n",
    "            recording = recording.iloc[:16000,:]\n",
    "\n",
    "            # FFT\n",
    "            fft_recording = FFT_Processing(recording)\n",
    "\n",
    "            # PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            pca_clip = pca.fit(fft_recording, train_labels).transform(fft_recording).T[0]\n",
    "\n",
    "           \n",
    "            if subject == 31:\n",
    "                test_data.append(recording)\n",
    "                test_labels.append(labels[playing])\n",
    "                test_pca.append(pca_clip)\n",
    "            else:\n",
    "                train_data.append(recording)\n",
    "                train_labels.append(labels[playing])\n",
    "                train_pca.append(pca_clip)\n",
    "                    \n",
    "print('Processing completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with dim 3. LinearDiscriminantAnalysis expected <= 2.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c7ce84b0d952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m--> 424\u001b[1;33m         X, y = self._validate_data(X, y, ensure_min_samples=2, estimator=self,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                    dtype=[np.float64, np.float32])\n\u001b[0;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    641\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. LinearDiscriminantAnalysis expected <= 2."
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_r2 = lda.fit(train_pca, train_labels).transform(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(119, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X_r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1440x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"589.79625pt\" version=\"1.1\" viewBox=\"0 0 1158.504688 589.79625\" width=\"1158.504688pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-03-17T22:18:12.164448</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 589.79625 \r\nL 1158.504688 589.79625 \r\nL 1158.504688 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 35.304688 565.918125 \r\nL 1151.304688 565.918125 \r\nL 1151.304688 22.318125 \r\nL 35.304688 22.318125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"mdd20c6496f\" style=\"stroke:#1f77b4;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"419.748544\" xlink:href=\"#mdd20c6496f\" y=\"106.973719\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"416.671627\" xlink:href=\"#mdd20c6496f\" y=\"106.200827\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"418.753615\" xlink:href=\"#mdd20c6496f\" y=\"105.911005\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"419.313254\" xlink:href=\"#mdd20c6496f\" y=\"107.196574\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"414.671636\" xlink:href=\"#mdd20c6496f\" y=\"107.734513\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"412.80621\" xlink:href=\"#mdd20c6496f\" y=\"112.97016\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"411.893802\" xlink:href=\"#mdd20c6496f\" y=\"109.998621\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_2\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"mae58e7d48d\" style=\"stroke:#ff7f0e;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"266.051496\" xlink:href=\"#mae58e7d48d\" y=\"193.558984\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"263.272483\" xlink:href=\"#mae58e7d48d\" y=\"195.310319\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"265.710459\" xlink:href=\"#mae58e7d48d\" y=\"191.094823\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"266.985086\" xlink:href=\"#mae58e7d48d\" y=\"190.85421\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"270.556158\" xlink:href=\"#mae58e7d48d\" y=\"194.580759\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"264.052868\" xlink:href=\"#mae58e7d48d\" y=\"221.24529\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"263.198838\" xlink:href=\"#mae58e7d48d\" y=\"162.643559\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_3\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m7a406e88b1\" style=\"stroke:#2ca02c;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"333.557692\" xlink:href=\"#m7a406e88b1\" y=\"112.672397\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"331.539829\" xlink:href=\"#m7a406e88b1\" y=\"108.014095\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"330.312216\" xlink:href=\"#m7a406e88b1\" y=\"111.824573\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"331.886547\" xlink:href=\"#m7a406e88b1\" y=\"110.319022\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"327.908832\" xlink:href=\"#m7a406e88b1\" y=\"110.093098\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"330.500576\" xlink:href=\"#m7a406e88b1\" y=\"115.234057\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"333.098627\" xlink:href=\"#m7a406e88b1\" y=\"116.537569\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"333.479152\" xlink:href=\"#m7a406e88b1\" y=\"112.204062\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"334.104954\" xlink:href=\"#m7a406e88b1\" y=\"118.388066\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"331.43268\" xlink:href=\"#m7a406e88b1\" y=\"111.651482\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"375.827917\" xlink:href=\"#m7a406e88b1\" y=\"120.322725\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"313.36156\" xlink:href=\"#m7a406e88b1\" y=\"112.141627\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"305.789811\" xlink:href=\"#m7a406e88b1\" y=\"135.088897\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"361.727485\" xlink:href=\"#m7a406e88b1\" y=\"71.721233\"/>\r\n     <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"315.996566\" xlink:href=\"#m7a406e88b1\" y=\"123.30579\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_4\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m5e66dd1060\" style=\"stroke:#d62728;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"526.836208\" xlink:href=\"#m5e66dd1060\" y=\"87.072088\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"530.251283\" xlink:href=\"#m5e66dd1060\" y=\"92.173907\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"530.1647\" xlink:href=\"#m5e66dd1060\" y=\"92.189272\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"532.703987\" xlink:href=\"#m5e66dd1060\" y=\"93.058807\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"531.060681\" xlink:href=\"#m5e66dd1060\" y=\"88.327417\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"530.068444\" xlink:href=\"#m5e66dd1060\" y=\"89.523594\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"527.390195\" xlink:href=\"#m5e66dd1060\" y=\"90.965247\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"529.172906\" xlink:href=\"#m5e66dd1060\" y=\"90.781638\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"529.82417\" xlink:href=\"#m5e66dd1060\" y=\"91.868561\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"529.117803\" xlink:href=\"#m5e66dd1060\" y=\"90.599964\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"531.186007\" xlink:href=\"#m5e66dd1060\" y=\"89.931101\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"527.487871\" xlink:href=\"#m5e66dd1060\" y=\"88.354826\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"528.978651\" xlink:href=\"#m5e66dd1060\" y=\"91.335546\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"547.888956\" xlink:href=\"#m5e66dd1060\" y=\"98.229627\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"521.306094\" xlink:href=\"#m5e66dd1060\" y=\"113.278327\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"531.334015\" xlink:href=\"#m5e66dd1060\" y=\"89.141361\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"554.427053\" xlink:href=\"#m5e66dd1060\" y=\"47.027216\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"557.906445\" xlink:href=\"#m5e66dd1060\" y=\"94.828815\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"491.96994\" xlink:href=\"#m5e66dd1060\" y=\"135.307401\"/>\r\n     <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"512.428792\" xlink:href=\"#m5e66dd1060\" y=\"68.481752\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_5\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"md5d90bc5b1\" style=\"stroke:#9467bd;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#9467bd;fill-opacity:0.8;stroke:#9467bd;stroke-opacity:0.8;\" x=\"353.225107\" xlink:href=\"#md5d90bc5b1\" y=\"131.153\"/>\r\n     <use style=\"fill:#9467bd;fill-opacity:0.8;stroke:#9467bd;stroke-opacity:0.8;\" x=\"351.270907\" xlink:href=\"#md5d90bc5b1\" y=\"132.539382\"/>\r\n     <use style=\"fill:#9467bd;fill-opacity:0.8;stroke:#9467bd;stroke-opacity:0.8;\" x=\"356.628877\" xlink:href=\"#md5d90bc5b1\" y=\"131.808093\"/>\r\n     <use style=\"fill:#9467bd;fill-opacity:0.8;stroke:#9467bd;stroke-opacity:0.8;\" x=\"346.118493\" xlink:href=\"#md5d90bc5b1\" y=\"133.512951\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_6\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m10b7ce90b9\" style=\"stroke:#8c564b;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"196.576757\" xlink:href=\"#m10b7ce90b9\" y=\"265.424068\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"200.118496\" xlink:href=\"#m10b7ce90b9\" y=\"258.917373\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"198.397149\" xlink:href=\"#m10b7ce90b9\" y=\"261.472408\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"199.996684\" xlink:href=\"#m10b7ce90b9\" y=\"263.873117\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"246.5621\" xlink:href=\"#m10b7ce90b9\" y=\"247.271021\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"210.205358\" xlink:href=\"#m10b7ce90b9\" y=\"273.394734\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"195.957813\" xlink:href=\"#m10b7ce90b9\" y=\"254.166658\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"253.245141\" xlink:href=\"#m10b7ce90b9\" y=\"295.284038\"/>\r\n     <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"101.131299\" xlink:href=\"#m10b7ce90b9\" y=\"237.483343\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_7\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"mba5f3505f0\" style=\"stroke:#e377c2;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1100.577415\" xlink:href=\"#mba5f3505f0\" y=\"259.353361\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1094.291765\" xlink:href=\"#mba5f3505f0\" y=\"258.109304\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1099.756063\" xlink:href=\"#mba5f3505f0\" y=\"260.060305\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1099.106648\" xlink:href=\"#mba5f3505f0\" y=\"260.91473\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1098.004373\" xlink:href=\"#mba5f3505f0\" y=\"257.511883\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1099.617729\" xlink:href=\"#mba5f3505f0\" y=\"259.379754\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1092.409021\" xlink:href=\"#mba5f3505f0\" y=\"251.372274\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1093.441693\" xlink:href=\"#mba5f3505f0\" y=\"237.260878\"/>\r\n     <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1079.91484\" xlink:href=\"#mba5f3505f0\" y=\"276.365057\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_8\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"mf1c92cfcb0\" style=\"stroke:#7f7f7f;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"148.766396\" xlink:href=\"#mf1c92cfcb0\" y=\"180.990248\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"144.836125\" xlink:href=\"#mf1c92cfcb0\" y=\"178.309768\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"144.706224\" xlink:href=\"#mf1c92cfcb0\" y=\"178.674494\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"142.554528\" xlink:href=\"#mf1c92cfcb0\" y=\"180.08251\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"143.383424\" xlink:href=\"#mf1c92cfcb0\" y=\"177.956179\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"141.571641\" xlink:href=\"#mf1c92cfcb0\" y=\"177.764687\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"142.44939\" xlink:href=\"#mf1c92cfcb0\" y=\"179.565157\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"140.951642\" xlink:href=\"#mf1c92cfcb0\" y=\"183.012326\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"113.140261\" xlink:href=\"#mf1c92cfcb0\" y=\"177.377039\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"155.104688\" xlink:href=\"#mf1c92cfcb0\" y=\"173.408286\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"185.281282\" xlink:href=\"#mf1c92cfcb0\" y=\"183.403973\"/>\r\n     <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"125.577871\" xlink:href=\"#mf1c92cfcb0\" y=\"179.713623\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_9\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m798bb9a38a\" style=\"stroke:#bcbd22;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"568.088006\" xlink:href=\"#m798bb9a38a\" y=\"99.88863\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"568.633292\" xlink:href=\"#m798bb9a38a\" y=\"105.577439\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"569.672414\" xlink:href=\"#m798bb9a38a\" y=\"99.493374\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"566.557603\" xlink:href=\"#m798bb9a38a\" y=\"103.307132\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"572.954788\" xlink:href=\"#m798bb9a38a\" y=\"100.68464\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"569.767082\" xlink:href=\"#m798bb9a38a\" y=\"104.690608\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"572.161552\" xlink:href=\"#m798bb9a38a\" y=\"101.782398\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"571.010019\" xlink:href=\"#m798bb9a38a\" y=\"101.727511\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"571.225393\" xlink:href=\"#m798bb9a38a\" y=\"129.270235\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"579.936245\" xlink:href=\"#m798bb9a38a\" y=\"107.506185\"/>\r\n     <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"550.876945\" xlink:href=\"#m798bb9a38a\" y=\"88.171624\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_10\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m1253d1336d\" style=\"stroke:#17becf;stroke-opacity:0.8;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"478.640811\" xlink:href=\"#m1253d1336d\" y=\"242.767792\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"479.669577\" xlink:href=\"#m1253d1336d\" y=\"237.792276\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"484.318529\" xlink:href=\"#m1253d1336d\" y=\"239.003755\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"484.612458\" xlink:href=\"#m1253d1336d\" y=\"241.362033\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"482.370301\" xlink:href=\"#m1253d1336d\" y=\"239.901231\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"480.474988\" xlink:href=\"#m1253d1336d\" y=\"239.949666\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"478.602619\" xlink:href=\"#m1253d1336d\" y=\"239.242938\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"478.432067\" xlink:href=\"#m1253d1336d\" y=\"245.106642\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"439.809352\" xlink:href=\"#m1253d1336d\" y=\"224.399913\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"536.026555\" xlink:href=\"#m1253d1336d\" y=\"225.696328\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"479.060104\" xlink:href=\"#m1253d1336d\" y=\"249.291635\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"469.370281\" xlink:href=\"#m1253d1336d\" y=\"222.225565\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"470.709456\" xlink:href=\"#m1253d1336d\" y=\"257.250375\"/>\r\n     <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"502.428341\" xlink:href=\"#m1253d1336d\" y=\"244.133456\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_11\">\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"90.796693\" xlink:href=\"#mdd20c6496f\" y=\"278.616113\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"89.243333\" xlink:href=\"#mdd20c6496f\" y=\"283.686549\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"93.372999\" xlink:href=\"#mdd20c6496f\" y=\"278.217465\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"91.398732\" xlink:href=\"#mdd20c6496f\" y=\"279.022611\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"90.112536\" xlink:href=\"#mdd20c6496f\" y=\"282.139599\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"86.03196\" xlink:href=\"#mdd20c6496f\" y=\"283.30135\"/>\r\n     <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"97.113974\" xlink:href=\"#mdd20c6496f\" y=\"273.526\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_12\">\r\n    <g clip-path=\"url(#pd5c8dc5df6)\">\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"487.121424\" xlink:href=\"#mae58e7d48d\" y=\"535.642248\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"491.758702\" xlink:href=\"#mae58e7d48d\" y=\"539.025671\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"491.893653\" xlink:href=\"#mae58e7d48d\" y=\"541.209034\"/>\r\n     <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"482.514804\" xlink:href=\"#mae58e7d48d\" y=\"528.188957\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m0f71d52cea\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.804689\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- −20 -->\r\n      <g transform=\"translate(68.252345 580.516562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.59375 35.5 \r\nL 73.1875 35.5 \r\nL 73.1875 27.203125 \r\nL 10.59375 27.203125 \r\nz\r\n\" id=\"DejaVuSans-8722\"/>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"252.668561\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- −10 -->\r\n      <g transform=\"translate(242.116217 580.516562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"426.532433\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(423.351183 580.516562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"600.396305\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(594.033805 580.516562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"774.260177\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(767.897677 580.516562)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"948.124049\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(941.761549 580.516562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1121.987921\" xlink:href=\"#m0f71d52cea\" y=\"565.918125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(1115.625421 580.516562)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m68bb647fda\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.304688\" xlink:href=\"#m68bb647fda\" y=\"531.803669\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- −30 -->\r\n      <g transform=\"translate(7.2 535.602888)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.304688\" xlink:href=\"#m68bb647fda\" y=\"414.950215\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- −20 -->\r\n      <g transform=\"translate(7.2 418.749434)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.304688\" xlink:href=\"#m68bb647fda\" y=\"298.096761\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- −10 -->\r\n      <g transform=\"translate(7.2 301.89598)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.304688\" xlink:href=\"#m68bb647fda\" y=\"181.243307\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(21.942187 185.042526)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.304688\" xlink:href=\"#m68bb647fda\" y=\"64.389853\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(15.579687 68.189072)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 35.304688 565.918125 \r\nL 35.304688 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 1151.304688 565.918125 \r\nL 1151.304688 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 35.304687 565.918125 \r\nL 1151.304688 565.918125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 35.304687 22.318125 \r\nL 1151.304688 22.318125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_13\">\r\n    <!-- LDA of IRIS dataset -->\r\n    <g transform=\"translate(535.635313 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 19.671875 64.796875 \r\nL 19.671875 8.109375 \r\nL 31.59375 8.109375 \r\nQ 46.6875 8.109375 53.6875 14.9375 \r\nQ 60.6875 21.78125 60.6875 36.53125 \r\nQ 60.6875 51.171875 53.6875 57.984375 \r\nQ 46.6875 64.796875 31.59375 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 30.078125 72.90625 \r\nQ 51.265625 72.90625 61.171875 64.09375 \r\nQ 71.09375 55.28125 71.09375 36.53125 \r\nQ 71.09375 17.671875 61.125 8.828125 \r\nQ 51.171875 0 30.078125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-68\"/>\r\n      <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n      <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n      <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-76\"/>\r\n     <use x=\"55.712891\" xlink:href=\"#DejaVuSans-68\"/>\r\n     <use x=\"130.964844\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"199.373047\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"231.160156\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"292.341797\" xlink:href=\"#DejaVuSans-102\"/>\r\n     <use x=\"327.546875\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"359.333984\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"388.826172\" xlink:href=\"#DejaVuSans-82\"/>\r\n     <use x=\"458.308594\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"487.800781\" xlink:href=\"#DejaVuSans-83\"/>\r\n     <use x=\"551.277344\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"583.064453\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"646.541016\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"707.820312\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"747.029297\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"808.308594\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"860.408203\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"921.931641\" xlink:href=\"#DejaVuSans-116\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 1037.670312 206.455625 \r\nL 1144.304688 206.455625 \r\nQ 1146.304688 206.455625 1146.304688 204.455625 \r\nL 1146.304688 29.318125 \r\nQ 1146.304688 27.318125 1144.304688 27.318125 \r\nL 1037.670312 27.318125 \r\nQ 1035.670312 27.318125 1035.670312 29.318125 \r\nL 1035.670312 204.455625 \r\nQ 1035.670312 206.455625 1037.670312 206.455625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"PathCollection_13\">\r\n     <g>\r\n      <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mdd20c6496f\" y=\"36.291562\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- HAPPY -->\r\n     <g transform=\"translate(1067.670312 38.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 43.015625 \r\nL 55.515625 43.015625 \r\nL 55.515625 72.90625 \r\nL 65.375 72.90625 \r\nL 65.375 0 \r\nL 55.515625 0 \r\nL 55.515625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-72\"/>\r\n       <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n       <path d=\"M -0.203125 72.90625 \r\nL 10.40625 72.90625 \r\nL 30.609375 42.921875 \r\nL 50.6875 72.90625 \r\nL 61.28125 72.90625 \r\nL 35.5 34.71875 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 34.71875 \r\nz\r\n\" id=\"DejaVuSans-89\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"143.603516\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"203.90625\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"261.958984\" xlink:href=\"#DejaVuSans-89\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_14\">\r\n     <g>\r\n      <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mae58e7d48d\" y=\"50.969687\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- FEAR -->\r\n     <g transform=\"translate(1067.670312 53.594687)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 51.703125 72.90625 \r\nL 51.703125 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.109375 \r\nL 48.578125 43.109375 \r\nL 48.578125 34.8125 \r\nL 19.671875 34.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-70\"/>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-70\"/>\r\n      <use x=\"57.519531\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"120.703125\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"189.111328\" xlink:href=\"#DejaVuSans-82\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_15\">\r\n     <g>\r\n      <use style=\"fill:#2ca02c;fill-opacity:0.8;stroke:#2ca02c;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#m7a406e88b1\" y=\"65.647812\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_16\">\r\n     <!-- ANGER -->\r\n     <g transform=\"translate(1067.670312 68.272812)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n       <path d=\"M 59.515625 10.40625 \r\nL 59.515625 29.984375 \r\nL 43.40625 29.984375 \r\nL 43.40625 38.09375 \r\nL 69.28125 38.09375 \r\nL 69.28125 6.78125 \r\nQ 63.578125 2.734375 56.6875 0.65625 \r\nQ 49.8125 -1.421875 42 -1.421875 \r\nQ 24.90625 -1.421875 15.25 8.5625 \r\nQ 5.609375 18.5625 5.609375 36.375 \r\nQ 5.609375 54.25 15.25 64.234375 \r\nQ 24.90625 74.21875 42 74.21875 \r\nQ 49.125 74.21875 55.546875 72.453125 \r\nQ 61.96875 70.703125 67.390625 67.28125 \r\nL 67.390625 56.78125 \r\nQ 61.921875 61.421875 55.765625 63.765625 \r\nQ 49.609375 66.109375 42.828125 66.109375 \r\nQ 29.4375 66.109375 22.71875 58.640625 \r\nQ 16.015625 51.171875 16.015625 36.375 \r\nQ 16.015625 21.625 22.71875 14.15625 \r\nQ 29.4375 6.6875 42.828125 6.6875 \r\nQ 48.046875 6.6875 52.140625 7.59375 \r\nQ 56.25 8.5 59.515625 10.40625 \r\nz\r\n\" id=\"DejaVuSans-71\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"68.408203\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"143.212891\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"220.703125\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"283.886719\" xlink:href=\"#DejaVuSans-82\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_16\">\r\n     <g>\r\n      <use style=\"fill:#d62728;fill-opacity:0.8;stroke:#d62728;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#m5e66dd1060\" y=\"80.325937\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_17\">\r\n     <!-- SURPRISE -->\r\n     <g transform=\"translate(1067.670312 82.950937)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 8.6875 72.90625 \r\nL 18.609375 72.90625 \r\nL 18.609375 28.609375 \r\nQ 18.609375 16.890625 22.84375 11.734375 \r\nQ 27.09375 6.59375 36.625 6.59375 \r\nQ 46.09375 6.59375 50.34375 11.734375 \r\nQ 54.59375 16.890625 54.59375 28.609375 \r\nL 54.59375 72.90625 \r\nL 64.5 72.90625 \r\nL 64.5 27.390625 \r\nQ 64.5 13.140625 57.4375 5.859375 \r\nQ 50.390625 -1.421875 36.625 -1.421875 \r\nQ 22.796875 -1.421875 15.734375 5.859375 \r\nQ 8.6875 13.140625 8.6875 27.390625 \r\nz\r\n\" id=\"DejaVuSans-85\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-85\"/>\r\n      <use x=\"136.669922\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"206.152344\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"266.455078\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"335.9375\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"365.429688\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"428.90625\" xlink:href=\"#DejaVuSans-69\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_17\">\r\n     <g>\r\n      <use style=\"fill:#9467bd;fill-opacity:0.8;stroke:#9467bd;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#md5d90bc5b1\" y=\"95.004062\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_18\">\r\n     <!-- HIGH VALENCE -->\r\n     <g transform=\"translate(1067.670312 97.629062)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 28.609375 0 \r\nL 0.78125 72.90625 \r\nL 11.078125 72.90625 \r\nL 34.1875 11.53125 \r\nL 57.328125 72.90625 \r\nL 67.578125 72.90625 \r\nL 39.796875 0 \r\nz\r\n\" id=\"DejaVuSans-86\"/>\r\n       <path d=\"M 64.40625 67.28125 \r\nL 64.40625 56.890625 \r\nQ 59.421875 61.53125 53.78125 63.8125 \r\nQ 48.140625 66.109375 41.796875 66.109375 \r\nQ 29.296875 66.109375 22.65625 58.46875 \r\nQ 16.015625 50.828125 16.015625 36.375 \r\nQ 16.015625 21.96875 22.65625 14.328125 \r\nQ 29.296875 6.6875 41.796875 6.6875 \r\nQ 48.140625 6.6875 53.78125 8.984375 \r\nQ 59.421875 11.28125 64.40625 15.921875 \r\nL 64.40625 5.609375 \r\nQ 59.234375 2.09375 53.4375 0.328125 \r\nQ 47.65625 -1.421875 41.21875 -1.421875 \r\nQ 24.65625 -1.421875 15.125 8.703125 \r\nQ 5.609375 18.84375 5.609375 36.375 \r\nQ 5.609375 53.953125 15.125 64.078125 \r\nQ 24.65625 74.21875 41.21875 74.21875 \r\nQ 47.75 74.21875 53.53125 72.484375 \r\nQ 59.328125 70.75 64.40625 67.28125 \r\nz\r\n\" id=\"DejaVuSans-67\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"104.6875\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"182.177734\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"289.160156\" xlink:href=\"#DejaVuSans-86\"/>\r\n      <use x=\"351.193359\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"419.601562\" xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"475.314453\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"538.498047\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"613.302734\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"683.126953\" xlink:href=\"#DejaVuSans-69\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_18\">\r\n     <g>\r\n      <use style=\"fill:#8c564b;fill-opacity:0.8;stroke:#8c564b;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#m10b7ce90b9\" y=\"109.682187\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_19\">\r\n     <!-- LOW VALENCE -->\r\n     <g transform=\"translate(1067.670312 112.307187)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 39.40625 66.21875 \r\nQ 28.65625 66.21875 22.328125 58.203125 \r\nQ 16.015625 50.203125 16.015625 36.375 \r\nQ 16.015625 22.609375 22.328125 14.59375 \r\nQ 28.65625 6.59375 39.40625 6.59375 \r\nQ 50.140625 6.59375 56.421875 14.59375 \r\nQ 62.703125 22.609375 62.703125 36.375 \r\nQ 62.703125 50.203125 56.421875 58.203125 \r\nQ 50.140625 66.21875 39.40625 66.21875 \r\nz\r\nM 39.40625 74.21875 \r\nQ 54.734375 74.21875 63.90625 63.9375 \r\nQ 73.09375 53.65625 73.09375 36.375 \r\nQ 73.09375 19.140625 63.90625 8.859375 \r\nQ 54.734375 -1.421875 39.40625 -1.421875 \r\nQ 24.03125 -1.421875 14.8125 8.828125 \r\nQ 5.609375 19.09375 5.609375 36.375 \r\nQ 5.609375 53.65625 14.8125 63.9375 \r\nQ 24.03125 74.21875 39.40625 74.21875 \r\nz\r\n\" id=\"DejaVuSans-79\"/>\r\n       <path d=\"M 3.328125 72.90625 \r\nL 13.28125 72.90625 \r\nL 28.609375 11.28125 \r\nL 43.890625 72.90625 \r\nL 54.984375 72.90625 \r\nL 70.3125 11.28125 \r\nL 85.59375 72.90625 \r\nL 95.609375 72.90625 \r\nL 77.296875 0 \r\nL 64.890625 0 \r\nL 49.515625 63.28125 \r\nL 33.984375 0 \r\nL 21.578125 0 \r\nz\r\n\" id=\"DejaVuSans-87\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"52.087891\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"130.798828\" xlink:href=\"#DejaVuSans-87\"/>\r\n      <use x=\"229.675781\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"261.462891\" xlink:href=\"#DejaVuSans-86\"/>\r\n      <use x=\"323.496094\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"391.904297\" xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"447.617188\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"510.800781\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"585.605469\" xlink:href=\"#DejaVuSans-67\"/>\r\n      <use x=\"655.429688\" xlink:href=\"#DejaVuSans-69\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_19\">\r\n     <g>\r\n      <use style=\"fill:#e377c2;fill-opacity:0.8;stroke:#e377c2;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mba5f3505f0\" y=\"124.360312\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_20\">\r\n     <!-- HIGH ENERGY -->\r\n     <g transform=\"translate(1067.670312 126.985312)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"104.6875\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"182.177734\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"289.160156\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"352.34375\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"427.148438\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"490.332031\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"559.814453\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"632.304688\" xlink:href=\"#DejaVuSans-89\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_20\">\r\n     <g>\r\n      <use style=\"fill:#7f7f7f;fill-opacity:0.8;stroke:#7f7f7f;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mf1c92cfcb0\" y=\"139.038437\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_21\">\r\n     <!-- LOW ENERGY -->\r\n     <g transform=\"translate(1067.670312 141.663437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"52.087891\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"130.798828\" xlink:href=\"#DejaVuSans-87\"/>\r\n      <use x=\"229.675781\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"261.462891\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"324.646484\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"399.451172\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"462.634766\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"532.117188\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"604.607422\" xlink:href=\"#DejaVuSans-89\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_21\">\r\n     <g>\r\n      <use style=\"fill:#bcbd22;fill-opacity:0.8;stroke:#bcbd22;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#m798bb9a38a\" y=\"153.716562\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_22\">\r\n     <!-- HIGH TENSION -->\r\n     <g transform=\"translate(1067.670312 156.341562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"104.6875\" xlink:href=\"#DejaVuSans-71\"/>\r\n      <use x=\"182.177734\" xlink:href=\"#DejaVuSans-72\"/>\r\n      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"289.160156\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"350.244141\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"413.427734\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"488.232422\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"551.708984\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"581.201172\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"659.912109\" xlink:href=\"#DejaVuSans-78\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_22\">\r\n     <g>\r\n      <use style=\"fill:#17becf;fill-opacity:0.8;stroke:#17becf;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#m1253d1336d\" y=\"168.394687\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_23\">\r\n     <!-- LOW TENSION -->\r\n     <g transform=\"translate(1067.670312 171.019687)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"52.087891\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"130.798828\" xlink:href=\"#DejaVuSans-87\"/>\r\n      <use x=\"229.675781\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"261.462891\" xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"322.546875\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"385.730469\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"460.535156\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"524.011719\" xlink:href=\"#DejaVuSans-73\"/>\r\n      <use x=\"553.503906\" xlink:href=\"#DejaVuSans-79\"/>\r\n      <use x=\"632.214844\" xlink:href=\"#DejaVuSans-78\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_23\">\r\n     <g>\r\n      <use style=\"fill:#1f77b4;fill-opacity:0.8;stroke:#1f77b4;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mdd20c6496f\" y=\"183.072812\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_24\">\r\n     <!-- SAD -->\r\n     <g transform=\"translate(1067.670312 185.697812)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"65.351562\" xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"133.759766\" xlink:href=\"#DejaVuSans-68\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_24\">\r\n     <g>\r\n      <use style=\"fill:#ff7f0e;fill-opacity:0.8;stroke:#ff7f0e;stroke-opacity:0.8;\" x=\"1049.670312\" xlink:href=\"#mae58e7d48d\" y=\"197.750937\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_25\">\r\n     <!-- TENDER -->\r\n     <g transform=\"translate(1067.670312 200.375937)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"124.267578\" xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"199.072266\" xlink:href=\"#DejaVuSans-68\"/>\r\n      <use x=\"276.074219\" xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"339.257812\" xlink:href=\"#DejaVuSans-82\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pd5c8dc5df6\">\r\n   <rect height=\"543.6\" width=\"1116\" x=\"35.304688\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "target_names = ['HAPPY', 'FEAR', 'ANGER', 'SURPRISE','HIGH VALENCE', 'LOW VALENCE', 'HIGH ENERGY', 'LOW ENERGY', 'HIGH TENSION', 'LOW TENSION', 'SAD', 'TENDER']\n",
    "\n",
    "for target_name in target_names:\n",
    "    plt.scatter(X_r2[[index for index, value in enumerate(train_labels) if value == target_name], 0], X_r2[[index for index, value in enumerate(train_labels) if value == target_name], 1], alpha=.8,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      prediction         label\n",
       "0          HAPPY        TENDER\n",
       "1          ANGER      SURPRISE\n",
       "2     LOW ENERGY      SURPRISE\n",
       "3     LOW ENERGY   LOW TENSION\n",
       "4    HIGH ENERGY         ANGER\n",
       "5    HIGH ENERGY          FEAR\n",
       "6    LOW VALENCE         ANGER\n",
       "7    LOW VALENCE   LOW TENSION\n",
       "8    HIGH ENERGY      SURPRISE\n",
       "9    HIGH ENERGY         HAPPY\n",
       "10   HIGH ENERGY      SURPRISE\n",
       "11   HIGH ENERGY         ANGER\n",
       "12   HIGH ENERGY    LOW ENERGY\n",
       "13    LOW ENERGY  HIGH TENSION\n",
       "14    LOW ENERGY         ANGER\n",
       "15   HIGH ENERGY      SURPRISE\n",
       "16           SAD         HAPPY\n",
       "17   HIGH ENERGY           SAD\n",
       "18    LOW ENERGY  HIGH VALENCE\n",
       "19      SURPRISE   LOW VALENCE\n",
       "20   HIGH ENERGY    LOW ENERGY\n",
       "21           SAD    LOW ENERGY\n",
       "22         HAPPY   LOW TENSION\n",
       "23   HIGH ENERGY  HIGH TENSION\n",
       "24    LOW ENERGY  HIGH VALENCE\n",
       "25   HIGH ENERGY  HIGH TENSION\n",
       "26    LOW ENERGY  HIGH VALENCE\n",
       "27  HIGH TENSION    LOW ENERGY\n",
       "28      SURPRISE   HIGH ENERGY\n",
       "29   LOW TENSION   HIGH ENERGY\n",
       "30   HIGH ENERGY   HIGH ENERGY\n",
       "31    LOW ENERGY   HIGH ENERGY\n",
       "32   LOW VALENCE         HAPPY\n",
       "33   HIGH ENERGY   LOW VALENCE\n",
       "34   HIGH ENERGY      SURPRISE\n",
       "35   LOW VALENCE   LOW TENSION\n",
       "36   HIGH ENERGY        TENDER\n",
       "37           SAD    LOW ENERGY"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAPPY</td>\n      <td>TENDER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ANGER</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOW ENERGY</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LOW ENERGY</td>\n      <td>LOW TENSION</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HIGH ENERGY</td>\n      <td>FEAR</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LOW VALENCE</td>\n      <td>ANGER</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HIGH ENERGY</td>\n      <td>HAPPY</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH TENSION</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LOW ENERGY</td>\n      <td>ANGER</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SAD</td>\n      <td>HAPPY</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>HIGH ENERGY</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SURPRISE</td>\n      <td>LOW VALENCE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>HAPPY</td>\n      <td>LOW TENSION</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>HIGH TENSION</td>\n      <td>LOW ENERGY</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SURPRISE</td>\n      <td>HIGH ENERGY</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LOW TENSION</td>\n      <td>HIGH ENERGY</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH ENERGY</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH ENERGY</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>LOW VALENCE</td>\n      <td>HAPPY</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW VALENCE</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>HIGH ENERGY</td>\n      <td>TENDER</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "lda100 = LinearDiscriminantAnalysis(n_components=11)\n",
    "X_r100 = lda100.fit(train_pca, train_labels)\n",
    "predictions = pd.DataFrame({'prediction': lda100.predict(test_pca), 'label': test_labels})\n",
    "predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      prediction         label  correct\n",
       "0          HAPPY        TENDER    False\n",
       "1          ANGER      SURPRISE    False\n",
       "2     LOW ENERGY      SURPRISE    False\n",
       "3     LOW ENERGY   LOW TENSION    False\n",
       "4    HIGH ENERGY         ANGER    False\n",
       "5    HIGH ENERGY          FEAR    False\n",
       "6    LOW VALENCE         ANGER    False\n",
       "7    LOW VALENCE   LOW TENSION    False\n",
       "8    HIGH ENERGY      SURPRISE    False\n",
       "9    HIGH ENERGY         HAPPY    False\n",
       "10   HIGH ENERGY      SURPRISE    False\n",
       "11   HIGH ENERGY         ANGER    False\n",
       "12   HIGH ENERGY    LOW ENERGY    False\n",
       "13    LOW ENERGY  HIGH TENSION    False\n",
       "14    LOW ENERGY         ANGER    False\n",
       "15   HIGH ENERGY      SURPRISE    False\n",
       "16           SAD         HAPPY    False\n",
       "17   HIGH ENERGY           SAD    False\n",
       "18    LOW ENERGY  HIGH VALENCE    False\n",
       "19      SURPRISE   LOW VALENCE    False\n",
       "20   HIGH ENERGY    LOW ENERGY    False\n",
       "21           SAD    LOW ENERGY    False\n",
       "22         HAPPY   LOW TENSION    False\n",
       "23   HIGH ENERGY  HIGH TENSION    False\n",
       "24    LOW ENERGY  HIGH VALENCE    False\n",
       "25   HIGH ENERGY  HIGH TENSION    False\n",
       "26    LOW ENERGY  HIGH VALENCE    False\n",
       "27  HIGH TENSION    LOW ENERGY    False\n",
       "28      SURPRISE   HIGH ENERGY    False\n",
       "29   LOW TENSION   HIGH ENERGY    False\n",
       "30   HIGH ENERGY   HIGH ENERGY     True\n",
       "31    LOW ENERGY   HIGH ENERGY    False\n",
       "32   LOW VALENCE         HAPPY    False\n",
       "33   HIGH ENERGY   LOW VALENCE    False\n",
       "34   HIGH ENERGY      SURPRISE    False\n",
       "35   LOW VALENCE   LOW TENSION    False\n",
       "36   HIGH ENERGY        TENDER    False\n",
       "37           SAD    LOW ENERGY    False"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>label</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAPPY</td>\n      <td>TENDER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ANGER</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOW ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LOW ENERGY</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HIGH ENERGY</td>\n      <td>FEAR</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LOW VALENCE</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HIGH ENERGY</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LOW ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SAD</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>HIGH ENERGY</td>\n      <td>SAD</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SURPRISE</td>\n      <td>LOW VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>HAPPY</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>HIGH TENSION</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SURPRISE</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LOW TENSION</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH ENERGY</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>LOW VALENCE</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>HIGH ENERGY</td>\n      <td>TENDER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "predictions['correct'] = predictions['prediction'] == predictions['label']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "89.25793895,   -618.14458216,\n        -1802.08629505,   1210.60624559,  -3750.73940904,  -2278.46680586,\n        -9840.58859144, -10672.44438338, -15207.13289524, -18551.16897356,\n       -18576.6324114 , -19894.2072655 , -16406.12560375,  -9813.06556202,\n        -9853.49867294, -10998.65365408,  -7806.86455228,  -8807.19902382,\n        -8315.8122856 ,  -7102.93175216,   -744.68525557,   1089.05968915,\n         7408.19016942,   8874.11308538,  13739.51518242,  15443.69504566,\n        14640.29498363,  13695.36604305,  12575.82341832,   5900.63164395,\n         8488.85417466,  10179.55762099,   8465.15128548,  10513.27561348,\n         6165.29537512,   2129.29826946,   -247.42528361,   1556.75464599,\n        -1324.68490308,  -1167.46895247,  -5882.43310061, -10666.40101962,\n       -10216.03287779, -11637.65251927, -10964.55497088, -15556.69928941,\n       -11228.50441916, -15375.14021622, -15939.74638724, -16436.19808524,\n       -19000.3169227 , -22573.20872516, -24671.77319909, -28195.27772908,\n       -28466.70488907, -26749.95347668, -26184.90666301, -25217.11290714]), array([ 51520.7123775 ,  52779.68280823,  52904.78280838,  53837.57161495,\n        55113.75734861,  46332.85419117,  49315.05691892,  49184.88726496,\n        47442.79729258,  44899.40368156,  49630.55631803,  44871.46969813,\n        43239.37271619,  38494.2766359 ,  33876.58695684,  29739.85618094,\n        26721.07803118,  21584.19956183,  19184.81085357,  15859.81487046,\n        11929.2810119 ,  10713.10621686,   7324.10839515,   7898.3212565 ,\n         3988.20691459,  -1797.05577675,  -3416.85343185,  -3591.85516902,\n        -4134.81568072,  -3347.26348587,  -3994.56385153,     67.45474613,\n         2776.17644118,   -171.42231623,   1454.5759379 ,    918.38413734,\n         3715.91800857,   4159.13397548,   2239.78853897,   1325.76929899,\n         4644.55530611,   3418.93926778,   1630.0551354 ,  -1972.0155541 ,\n        -4974.34054459,  -9729.72503123, -12029.10465204, -12492.27546168,\n       -12893.33309432,  -9613.30522334, -14628.29809241, -13088.92877331,\n       -13154.4611141 , -14883.12412534, -16634.40649585, -17018.14652049,\n       -21687.46566656, -22317.98797077, -20733.76426247, -17136.09802929,\n       -16672.4808198 ,  -9882.82662691,  -6461.00535587,  -5256.69023978,\n        -6634.92924643,  -3692.18678723,  -3845.02644847,  -5340.42661406,\n        -8424.4701112 ,  -8987.57337636,  -6934.69858957,   -285.26045751,\n         1037.90577101,   1874.40505389,   2267.17554597,  -3685.85978118,\n        -3638.04190345,  -7645.54501077,  -7252.32718175,  -3049.80186477,\n        -7109.30517115,  -4339.19949168,  -8096.20660033,  -9525.58720553,\n        -8622.03028894,  -9487.4347393 ,  -6988.01390517, -10662.98267709,\n       -14377.89448171, -18674.92041445, -15580.99271505, -10570.47945653,\n       -12314.32456178, -12194.77052496, -18424.48626212, -15955.81758717,\n       -17028.95067899, -18798.44958918, -19741.82565052, -20668.12269944,\n       -20413.2889235 , -22727.01689388, -25496.43331309, -28592.82786999,\n       -27839.49640495, -24748.31550348, -22804.50839378, -21258.19763629,\n       -20020.78900004, -23267.16743671, -20329.97695529, -20127.21531861]), array([ 27226.04559204,  28255.32006451,  12199.46759005,   7391.11712234,\n         1676.70224376,   2530.91496109,   1541.53302658,   -267.20352562,\n        -1771.95737808,  -3203.56989004,  -6774.9223087 ,  -9743.10890419,\n       -14430.86532511, -15570.72295583, -13562.0209232 , -13450.79771873,\n       -13135.35203363, -15599.26485394, -14183.11004369, -12571.80336278,\n       -14323.0463655 , -11411.23027457, -12696.47294252,  -5547.98986722,\n       -11567.35174544,  -4136.64295843,  -6940.49110089,  -3291.09484293,\n        -2836.79291068,  -3644.97647497,  -6210.50027619,  -6143.78379507,\n        -6774.18305831,  -5191.84211001,  -2559.50550901,  -3478.40019903,\n        -1865.25734582,  -2644.40477556,   -524.87431651,  -2925.43968483,\n        -4980.09231624,  -2965.65686641,  -6488.92600906,  -4562.03796301,\n       -10062.25111441, -11695.24614072,  -5162.7938502 ,    542.83594089,\n         -954.41486756,  -6345.71718991,  -2588.13930412, -10234.95704854,\n        -7891.3595982 ,  -8177.588546  ,  -9540.3990327 ,  -8232.32445604,\n        -4311.14747367,   -393.09071877,  -2577.51415467,   -628.77705212,\n        -1410.120001  ,    174.42596579,  -2042.15156273,   1162.24594086,\n        -4503.38072626,  -5610.28295997,  -4872.92821017,  -4364.23678562,\n        -4971.1859585 ,  -4626.34792725,  -8246.91084778,  -4573.19702707,\n        -7156.69003042,  -8954.17965269,  -7929.08771081,  -4256.86182323,\n          166.84516745,   1267.36672341,   3360.61301685,   3637.98440428,\n         2808.88643056,   7469.71645299,  13049.5077428 ,   9236.26009313,\n        11282.04903868,  13817.75318977,  15719.93004978,  16040.51838412,\n        17558.99554942,  18093.11643541,  16078.48363424,  25244.83537384,\n        16830.43887169,  15869.76457847,  13957.7577996 ,  14009.21994953,\n        13316.9863264 ,  15563.45625351,  15069.78515936,  11685.88533895,\n         7079.97404807,   6790.35233707,   4919.09514383,   6304.87152661,\n         6118.11843496,   4075.07263249,   8344.54500504,  13827.29335473,\n         4455.72727709,  -1632.73494322,  -2604.98894121,  -1225.11558469]), array([ -6029.69327743,  -6229.8168524 ,  -5173.83223976,  -6196.8199412 ,\n       -10248.37170802,  -7867.39479119,  -7234.1898155 ,  -6899.47962745,\n        -7739.51349603,  -6747.87832332,  -5572.64698515,  -5694.50641433,\n        -6792.72813152,  -4675.80564141,  -4006.38617918,  -3121.40811895,\n        -2996.33435912,  -2098.24042329,  -2357.99199021,  -4549.96824795,\n        -6435.33721776,  -6410.53884605,  -4797.55491635,  -4395.42694699,\n        -3933.80880826,  -4418.27190974,  -6178.91792317,  -8609.28005401,\n       -10849.33358312, -12241.15955994, -12747.22948429, -12353.4964836 ,\n       -12440.22909588, -13110.13063617, -11999.2221127 ,  -8454.10207487,\n        -8795.03669976, -10018.91914805,  -8369.91995089,  -7973.08519375,\n        -6716.31006394, -10600.59620978,  -8656.99171201,  -9543.20428763,\n        -9416.88509567,  -7168.95944194,  -9536.81168509,  -9024.65996971,\n       -12312.55227913, -10122.36039534, -13409.00542248, -13178.74951881,\n        -4771.07872222,  13460.07014904,   2498.00416439,   3279.3664059 ,\n           70.8379595 ,   2537.12585073,    608.30813901,    828.52243197,\n         -705.40849562,   1035.21171314,  68588.21264753,  33770.80372293,\n        35482.15190766,  36252.89449689,  35778.38669746,  35861.64188413,\n        37451.53158687,  32741.92012247,  36672.44259407,  36344.95639527,\n        36787.36275093,  35326.65974767,  35819.77608457,  34970.69541138,\n        35689.19770068,  31214.2532809 ,  46694.6802712 ,   5136.43011468,\n        -1628.4197901 ,  -2298.92247497,  -4478.31169476,  -3647.29690306,\n        -6093.04908524, -11284.40163282, -12016.25336023, -11736.33769868,\n        -7186.33413445, -11143.22728845,  -6096.13876009,  -7970.87650514,\n        -2373.23598144, -11301.30574672,  -6447.08317675,  -8612.27651272,\n        -8942.14733229,  -6000.11463175,  -6215.87673073,  -7407.8976004 ,\n        -5674.1415406 ,  -8395.59281919,  -7069.15227404,  -9170.39634493,\n        -8559.03923977,  -8843.65754297,  -8178.43981367, -10997.49626538,\n       -12331.28654645, -11983.49450945, -13501.34753944, -15390.31224613]), array([ 63721.24244268,  55437.60482284,  56353.70341741,  54593.36076181,\n        59291.42736592,  62085.76863957,  56518.30843906,  50923.36665629,\n        54114.30013716,  51258.75876634,  47060.65356597,  35752.05082017,\n        32598.43100109,  27521.72958121,  27508.97731665,  26426.65099276,\n        24320.82596934,  18136.87056633,  14622.34594249,   8265.92761273,\n         6192.48076386,   2076.9167132 ,    907.65148522,    888.42671924,\n         -668.40960312,  -4517.74880769,  -4473.35670064,  -6075.07826696,\n        -5086.93794458,  -6692.14635624,  -5225.40110204,  -6013.06587597,\n        -5494.39378267,  -5927.56157927,  -6495.12077218,  -8863.1332499 ,\n        -9231.98048081, -10436.45877469, -12324.2494574 , -15167.90912239,\n       -19578.1274136 , -21040.05980631, -22963.74426678, -26130.41171851,\n       -24998.12726145, -25424.50893617, -25715.53306925, -27305.25809266,\n       -30623.1051202 , -29752.38186466, -31764.89143803, -27299.02127292,\n       -21969.21314901, -22130.41492291, -13690.24038227,  -8653.65301164,\n        -9900.7138294 ,  -9291.72658819,  -7451.07278133,  -6503.66165494,\n        -4374.22843856,  -5778.11549154,  -2635.2179204 ,  -1982.32427981,\n         -354.45506562,   -202.30424844,   1444.94264396,  -3165.33011539,\n        -7794.42518478,  -3134.47269301,  -6659.53456173,  -6935.39645865,\n        -5113.87021111,  -8194.04341137, -10592.27946513, -11321.31925148,\n       -11762.45413682, -13426.94079882, -12794.68809668, -13133.88957727,\n       -11794.84529434,  -8186.74820243,  -7540.1934573 ,  -8654.74518069,\n        -4119.76674803,  -4682.37687928,  -8212.303991  ,  -8709.92793478,\n        -7438.79541941, -10013.93100944, -10024.96989558, -14018.96494362,\n       -10963.84754102, -13665.91038983,  -9838.30300698,  -8006.12097416,\n        -9595.18631951, -10260.80583542,  -8314.63538054,  -6038.92716551,\n        -2557.03858241,  -3188.86991286,  -5745.3427143 ,  -4146.11060426,\n        -2311.62100986,  -1546.75214574,    989.71612404,   3354.33747464,\n         2875.98219024,   3150.63505948,   4312.78044944,   1104.97396056]), array([-32716.08048135, -39867.5282798 , -43663.54013984, -50400.94704288,\n       -52105.10320317, -49682.99684705, -52316.9015185 , -53891.21611618,\n       -52263.65112857, -52518.46081868, -53548.76909354, -52954.45327148,\n       -51918.24513313, -52606.94674583, -50625.57577552, -52235.55199735,\n       -49079.45880023, -39209.59140149, -39503.56968229, -38423.49140155,\n       -39116.9284598 , -36978.46583729, -31489.20268071, -32362.0447404 ,\n       -31873.64765059, -32883.12557224, -31514.48769881, -29987.8860643 ,\n       -29309.97153947, -28246.96414996, -24811.56813703, -22187.93982443,\n       -16336.2447473 , -16134.59033518, -16075.15369152, -17170.43646113,\n       -15142.35922201, -21427.07517773, -23431.15082326, -25735.82837471,\n       -26863.48105122, -28274.24881033, -28453.33966502, -30929.99931066,\n       -29300.19465945, -30807.67891624, -30413.70585672, -19279.04924584,\n        -6127.50006761,   -387.68549241,  -3428.64031382,  -3125.93278568,\n          113.5066541 ,  15456.07710227,   6591.55840727,   5040.62698644,\n         6041.63436688,   9194.85445637,   9980.36761874,  18264.01076135,\n        21028.57813299,  20114.20222521,  20882.51019236,  19118.52944221,\n        13240.48424444,  11748.90860683,  11619.72417423,  15426.70116508,\n        15768.58106541,  21056.1481508 ,  19488.29858316,  23792.44200882,\n        21941.93827708,  26293.13082335,  26192.90952953,  24008.8574846 ,\n        22573.61771567,  25992.66887512,  27142.08018524,  22713.71355103,\n        20326.24562574,  15548.8396555 ,  12217.86783787,  13064.60495003,\n        21563.0554124 ,  19516.42454246,  20028.47491597,  17887.50702182,\n        17949.27458915,  16078.29535538,  16747.26778771,  20318.8015332 ,\n        15482.61894875,  16304.030809  ,  21509.35565378,  28461.44005216,\n        41838.64348423,  52269.75873213,  57046.68419368,  56184.96153081,\n        63298.8989554 ,  62785.67929084,  60181.49904872,  62194.86778759,\n        62127.79142652,  63191.9839597 ,  65249.76926179,  62458.46862435,\n        62787.04761418,  58908.48877407,  59192.22141683,  55591.076663  ]), array([-15519.83235599, -17269.96163126, -27984.77858886, -27385.79749234,\n       -28543.45497428, -28871.97525211, -28550.2171002 , -29474.80526081,\n       -32419.7926066 , -34633.68447234, -34862.29739857, -37724.99150346,\n       -37712.79295341, -37625.22683556, -33279.42882146, -33158.92105937,\n       -33839.97066412, -36553.36380947, -35071.5495317 , -36596.18075972,\n       -42322.43614117, -42926.7543129 , -41248.10544052, -39462.32060893,\n       -38332.16586866, -38853.04084751, -41758.76469987, -42591.81958946,\n       -43012.43601791, -37050.52070463, -43941.00416121, -39679.21470434,\n       -36377.23165582, -34762.74542855, -36070.39011878, -34782.79903661,\n       -28893.7363901 , -28772.96347361, -30007.13274149, -30087.67362055,\n       -26095.51436718, -27309.74234065, -24450.58200646, -19660.93960701,\n       -24021.32150261, -19965.09554711, -23698.58026986, -19645.44600919,\n       -16412.75464136, -11883.24531132, -11861.03868471,  -8156.77717953,\n       -10822.66302116, -12327.81967649, -10967.92147498,  -7928.16818701,\n        -5657.37169974,  -4404.74068103,  -9167.09632143,  -7986.58862561,\n        -5082.42097032,   9138.94699267,  20549.34287764,  21876.3955294 ,\n        37056.48540748,  56637.4769795 ,  59631.67149354,  64312.59924784,\n        67007.10433965,  69657.16954959,  70178.92137907,  71627.22095299,\n        70249.64445051,  75011.39924805,  76816.50425708,  84029.35757876,\n        86259.55265254,  83234.75937688,  82666.28600354,  77728.39151483,\n        72738.79411948,  61702.40262634,  54475.08183477,  54168.53475906,\n        51226.93821401,  51395.25367416,  50458.3530136 ,  52242.26513708,\n        49295.51669124,  46541.57859274,  36481.1070951 ,  13873.53022853,\n        12948.45180148,  11447.11142212,   7320.19958393,   4841.5465459 ,\n         1763.95694347,  -1676.33358603,  -2644.37648291,  -3259.79862805,\n         1262.27069607,   1489.80619617,  -1494.45994226,  -6339.81850036,\n        -6640.79906824,  -3394.46048544,  -5701.43741375, -19287.91028231,\n       -26025.22195355, -22587.30664508, -18078.43012974, -16693.46913008]), array([ -9870.04846065,  -4390.23844821,   3327.78777321,   5955.46084548,\n         6063.7117055 ,   7511.82378845,  11747.34964467,  12043.73548847,\n        11766.86315726,   -966.70656845,    978.47871102,  -1451.1409878 ,\n        -3261.64648903, -13488.65587696, -14266.39078126, -13297.30081462,\n       -19649.22433279, -21430.58045462, -28432.41478236, -29513.88850771,\n       -31722.5230529 , -31491.6906409 , -30816.26401716, -24582.17309478,\n       -12201.57312723,  -3409.69839129,  -5556.7141832 ,  -3272.66496064,\n        -2710.25207857,  -2438.20891924,   1708.07834907,  -5955.05370456,\n        -2596.20924453,  -2116.12659186,  -6758.62392124,  -9766.42597049,\n        -9327.31129672, -13891.93819461, -11800.36773992, -23355.69113789,\n       -27971.42657023, -29177.76710635, -33825.2123549 , -37774.53996623,\n       -41157.39715721, -38462.60345174, -41485.68368658, -34071.4019282 ,\n       -38387.17193697, -40784.7311578 , -33298.15718919, -33548.41080306,\n       -35439.45030149, -34489.32358221, -29068.33207925, -30190.24173095,\n       -27624.1325044 , -30151.59725311, -28699.64156517, -20772.79967654,\n       -18437.63271507, -17967.32048405, -15855.21555092, -12634.84266734,\n       -12005.11110639, -10974.03935282, -15211.08924713, -11059.79178268,\n        -9592.29793061,  -4166.22966949,  -5090.54062856,   7635.8408696 ,\n         2167.08768378,   2483.59383415,   1879.43433117,  -3348.4486464 ,\n        -3954.39775816,  -7224.61048088,  -6711.09370913,  -2958.70592512,\n        -2903.28975339,   1862.60569468,  11219.9598454 ,  13978.95850786,\n        19670.91964084,  30369.67749059,  40966.692667  ,  40426.08451981,\n        40877.9754443 ,  46362.89040019,  46751.26079396,  44387.43030812,\n        54830.57787416,  60012.58303354,  58846.20839056,  56354.00324893,\n        54511.70757349,  47192.11116248,  47760.56872781,  49423.23974851,\n        54545.06222171,  50260.34512977,  44901.04828067,  34233.64089788,\n        36440.34968287,  29256.61717017,  31036.79210564,  32668.18699838,\n        27682.87364098,  14046.16450773,  12388.23765425,  11728.40663774]), array([-18897.82222189, -15122.36932047, -17969.09227854, -29823.68738785,\n       -29071.60938801, -27129.13395784, -25684.59988546, -20839.57737371,\n       -25451.82496538, -24737.29187412, -28547.26676678, -25736.08243932,\n       -29195.9486889 , -29685.98400484, -26260.97633741, -26029.62775925,\n       -25327.93047701, -28036.50611712, -28041.17803478, -24923.71701257,\n       -17634.28312235, -22020.31989206, -20941.99959752, -20568.80700095,\n       -22809.36091436, -23149.13370925, -24514.61499279, -26276.93558051,\n       -26103.87980925, -26348.75593355, -22117.99270118, -24707.37868345,\n       -25046.8672735 , -27916.05976512, -31279.82056085, -35806.37187532,\n       -42688.24947405, -42023.76288456, -44817.93651047, -43266.21658077,\n       -41803.68140896, -34402.98242144, -29031.41459774, -19371.07498841,\n        -8293.00774632,  -9365.58230023,  -2408.66331999,  63071.37973046,\n        46799.83215374,  50458.89221729,  49968.47509048,  51001.33968131,\n        52681.80749474,  53375.75352109,  56749.35619311,  56277.11358399,\n        55732.15240926,  54924.20984264,  57329.9901879 ,  56321.90996399,\n        59866.24946456,  65592.62557215,  47677.67137016,  30367.6949947 ,\n        15908.73592096,   9959.75209613,   9739.75299463,   7161.97091687,\n         7396.52777368,   4364.76941479,   7157.01961375,   8657.24312098,\n         9388.02471006,  13848.66541259,  14679.75079776,  11095.79747255,\n         8521.05460087,   2294.16834795,   -619.67522715,  -1333.84230089,\n          459.53266083,    813.79784069,  -1034.70790458,   2134.91835366,\n          902.4419854 ,   1165.06537454,   3101.93579446,   4101.74635061,\n         8467.6829901 ,  -3540.34952465,  -9444.36950002, -13451.59692212,\n       -11798.68155029,  -7934.61438596,  -5713.64635756,  -4960.59337752,\n        -4046.9426746 ,  -6444.55259662,  -5361.65198847,  -7686.07546487,\n        -4644.68526407,  -5184.10274887,  -9117.7238844 ,   7946.60027623,\n        22628.90437761,  29118.92538319,  30089.17740553,  31906.84907505,\n        33665.86807026,  37156.39454196,  35460.51393927,  36055.15052428]), array([-1.26060856e+04, -1.07968609e+04, -1.34245741e+04, -1.54798754e+04,\n       -1.66343834e+04, -1.60097307e+04, -1.88676693e+04, -1.41346433e+04,\n       -1.21495299e+04, -1.72244094e+04, -1.63595030e+04, -1.93197932e+04,\n       -1.91659469e+04, -1.56583122e+04, -2.26904251e+04, -2.16826526e+04,\n       -1.64879615e+04, -2.25394542e+04, -2.29141227e+04, -2.44376677e+04,\n       -2.15904559e+04, -2.13657595e+04, -1.92086890e+04, -1.94980661e+04,\n       -1.54947719e+04, -1.43143072e+04, -1.41693362e+04, -1.52891494e+04,\n       -1.16212999e+04, -8.95512671e+03, -9.59079218e+03, -1.13287731e+04,\n       -1.01566469e+04, -5.46134213e+03, -3.84083673e+03, -2.40636652e+03,\n        7.35522213e+02, -1.88703068e+03, -1.10880458e+03,  1.12358073e+03,\n        6.57438168e+01, -9.59825842e+02, -2.97191490e+03, -3.62675793e+03,\n       -7.40839856e+03, -6.84333538e+03, -5.74630320e+03, -5.52990063e+03,\n       -7.65026539e+03, -4.38885928e+03, -4.68705788e+03, -8.97130593e+03,\n       -1.07349182e+04, -1.31943924e+04, -1.33609225e+04, -9.46243993e+03,\n       -7.30063106e+03, -7.75359674e+03, -4.71813021e+03, -5.77293050e+03,\n       -4.80596189e+03, -1.87661581e+03, -1.55100520e+03, -1.72287744e+03,\n       -4.18343163e+03, -7.44175746e+03, -9.63813513e+03, -9.97272013e+03,\n       -8.85609786e+03, -9.46544996e+03, -1.09387779e+04, -6.26432090e+03,\n       -1.09344237e+04, -1.03051353e+04, -3.97675743e+02, -4.86586543e+03,\n       -6.01254846e+03, -3.93059140e+03, -6.14345515e+03, -5.84042764e+03,\n       -4.52445381e+03,  1.71648397e+01,  3.14069919e+03,  5.02804151e+03,\n        1.41884673e+04,  2.06034857e+04,  4.80261817e+04,  4.83527799e+04,\n        4.99264624e+04,  5.70663743e+04,  5.55975716e+04,  5.53044006e+04,\n        5.66949902e+04,  5.57237185e+04,  5.37523034e+04,  5.33043728e+04,\n        5.16590865e+04,  5.17232142e+04,  4.77537552e+04,  4.88680051e+04,\n        4.78992135e+04,  4.62767423e+04,  4.69600603e+04,  1.70801058e+04,\n        4.76603573e+03,  1.60346941e+03, -8.49491150e+03, -1.74439844e+04,\n       -2.46879153e+04, -2.36653355e+04, -2.67336199e+04, -2.55910120e+04])]\n"
     ]
    }
   ],
   "source": [
    "print(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'prediction': lda.predict(test_pca), 'label': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      prediction         label  correct\n",
       "0          HAPPY        TENDER    False\n",
       "1          ANGER      SURPRISE    False\n",
       "2     LOW ENERGY      SURPRISE    False\n",
       "3     LOW ENERGY   LOW TENSION    False\n",
       "4    HIGH ENERGY         ANGER    False\n",
       "5    HIGH ENERGY          FEAR    False\n",
       "6    LOW VALENCE         ANGER    False\n",
       "7    LOW VALENCE   LOW TENSION    False\n",
       "8    HIGH ENERGY      SURPRISE    False\n",
       "9    HIGH ENERGY         HAPPY    False\n",
       "10   HIGH ENERGY      SURPRISE    False\n",
       "11   HIGH ENERGY         ANGER    False\n",
       "12   HIGH ENERGY    LOW ENERGY    False\n",
       "13    LOW ENERGY  HIGH TENSION    False\n",
       "14    LOW ENERGY         ANGER    False\n",
       "15   HIGH ENERGY      SURPRISE    False\n",
       "16           SAD         HAPPY    False\n",
       "17   HIGH ENERGY           SAD    False\n",
       "18    LOW ENERGY  HIGH VALENCE    False\n",
       "19      SURPRISE   LOW VALENCE    False\n",
       "20   HIGH ENERGY    LOW ENERGY    False\n",
       "21           SAD    LOW ENERGY    False\n",
       "22         HAPPY   LOW TENSION    False\n",
       "23   HIGH ENERGY  HIGH TENSION    False\n",
       "24    LOW ENERGY  HIGH VALENCE    False\n",
       "25   HIGH ENERGY  HIGH TENSION    False\n",
       "26    LOW ENERGY  HIGH VALENCE    False\n",
       "27  HIGH TENSION    LOW ENERGY    False\n",
       "28      SURPRISE   HIGH ENERGY    False\n",
       "29   LOW TENSION   HIGH ENERGY    False\n",
       "30   HIGH ENERGY   HIGH ENERGY     True\n",
       "31    LOW ENERGY   HIGH ENERGY    False\n",
       "32   LOW VALENCE         HAPPY    False\n",
       "33   HIGH ENERGY   LOW VALENCE    False\n",
       "34   HIGH ENERGY      SURPRISE    False\n",
       "35   LOW VALENCE   LOW TENSION    False\n",
       "36   HIGH ENERGY        TENDER    False\n",
       "37           SAD    LOW ENERGY    False"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>label</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAPPY</td>\n      <td>TENDER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ANGER</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOW ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LOW ENERGY</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HIGH ENERGY</td>\n      <td>FEAR</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LOW VALENCE</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HIGH ENERGY</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HIGH ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LOW ENERGY</td>\n      <td>ANGER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SAD</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>HIGH ENERGY</td>\n      <td>SAD</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>SURPRISE</td>\n      <td>LOW VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>HAPPY</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>HIGH TENSION</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>SURPRISE</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LOW TENSION</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>HIGH ENERGY</td>\n      <td>HIGH ENERGY</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LOW ENERGY</td>\n      <td>HIGH ENERGY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>LOW VALENCE</td>\n      <td>HAPPY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>HIGH ENERGY</td>\n      <td>LOW VALENCE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>HIGH ENERGY</td>\n      <td>SURPRISE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>LOW VALENCE</td>\n      <td>LOW TENSION</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>HIGH ENERGY</td>\n      <td>TENDER</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SAD</td>\n      <td>LOW ENERGY</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "predictions['correct'] = predictions['prediction'] == predictions['label']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['TENDER', 'SURPRISE', 'SURPRISE', 'LOW TENSION', 'ANGER', 'FEAR', 'ANGER', 'LOW TENSION', 'SURPRISE', 'HAPPY', 'SURPRISE', 'ANGER', 'LOW ENERGY', 'HIGH TENSION', 'ANGER', 'SURPRISE', 'HAPPY', 'SAD', 'HIGH VALENCE', 'LOW VALENCE', 'LOW ENERGY', 'LOW ENERGY', 'LOW TENSION', 'HIGH TENSION', 'HIGH VALENCE', 'HIGH TENSION', 'HIGH VALENCE', 'LOW ENERGY', 'HIGH ENERGY', 'HIGH ENERGY', 'HIGH ENERGY', 'HIGH ENERGY', 'HAPPY', 'LOW VALENCE', 'SURPRISE', 'LOW TENSION', 'TENDER', 'LOW ENERGY']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ -9096.11014383 -13834.4766661  -11464.39462907 -14122.869196\n -13295.05578388 -13200.99249399 -24435.5996081  -15071.40389288\n -20271.21412239 -18624.32254758 -19950.73309618 -14073.0619853\n -17591.45966508 -12635.32331797 -18912.33847054 -15128.64749886\n -11572.06410814 -10696.43986866 -16337.29977285 -21025.5033695\n -18464.40869802 -16670.4438422  -17415.81054551 -22432.79320939\n -21737.07395599 -21189.70001868 -25730.55324256 -26694.08690477\n -20315.53851809  -8957.83557598 -18896.65622316 -13977.80867132\n -16636.1881002  -11010.2741852  -15276.46930391  -8404.88821117\n -12146.32682962 -14351.08289647 -14422.00268194 -10421.59585512\n -12938.76543666 -13332.70977998 -11172.91116171  44086.34065423\n  50238.66162822  43111.63893464  41465.53550933  42188.61610342\n  44563.12502598  44720.39689767  43481.11598319  45239.83176013\n  44618.90095285  46299.31235431  44894.33766178  46600.18073419\n  43498.95295692  48145.59286823  40899.95438343  79234.77933436\n   5507.62653185  -9837.18208643 -13721.56377795 -13452.7432711\n -18349.27935192 -19047.03254538 -18813.60165647 -16083.06267704\n -16612.632658   -15694.17615297 -14834.12918514 -15050.90614021\n -14671.27329837 -16016.54726376  40282.2178711   17462.50325434\n  17242.74596524  17445.9697373   18277.8111229   18471.89432635\n  18841.31080529  19918.00395383  19982.96067755  22803.10252655\n  23641.63232647  23699.60996584  27020.37879633  26477.47639895\n  29624.85143767  21418.80338032  11195.11720641  -7422.69311699\n -12321.67975483  -8939.5485368   -8210.78606852 -11295.29291854\n -13345.99426694 -12252.29409188 -10536.15667672 -15563.16303962\n -11662.99590443 -15645.54161528 -17923.26834686 -16892.15799757\n -18604.61384286 -16815.81240033 -16202.42632031 -19225.58971046\n -15180.76427714 -12206.07816018 -13613.3174655  -12621.75136617].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1a80c2604580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_pca\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1a80c2604580>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_pca\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m    562\u001b[0m         \u001b[1;31m# Only override for the doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ -9096.11014383 -13834.4766661  -11464.39462907 -14122.869196\n -13295.05578388 -13200.99249399 -24435.5996081  -15071.40389288\n -20271.21412239 -18624.32254758 -19950.73309618 -14073.0619853\n -17591.45966508 -12635.32331797 -18912.33847054 -15128.64749886\n -11572.06410814 -10696.43986866 -16337.29977285 -21025.5033695\n -18464.40869802 -16670.4438422  -17415.81054551 -22432.79320939\n -21737.07395599 -21189.70001868 -25730.55324256 -26694.08690477\n -20315.53851809  -8957.83557598 -18896.65622316 -13977.80867132\n -16636.1881002  -11010.2741852  -15276.46930391  -8404.88821117\n -12146.32682962 -14351.08289647 -14422.00268194 -10421.59585512\n -12938.76543666 -13332.70977998 -11172.91116171  44086.34065423\n  50238.66162822  43111.63893464  41465.53550933  42188.61610342\n  44563.12502598  44720.39689767  43481.11598319  45239.83176013\n  44618.90095285  46299.31235431  44894.33766178  46600.18073419\n  43498.95295692  48145.59286823  40899.95438343  79234.77933436\n   5507.62653185  -9837.18208643 -13721.56377795 -13452.7432711\n -18349.27935192 -19047.03254538 -18813.60165647 -16083.06267704\n -16612.632658   -15694.17615297 -14834.12918514 -15050.90614021\n -14671.27329837 -16016.54726376  40282.2178711   17462.50325434\n  17242.74596524  17445.9697373   18277.8111229   18471.89432635\n  18841.31080529  19918.00395383  19982.96067755  22803.10252655\n  23641.63232647  23699.60996584  27020.37879633  26477.47639895\n  29624.85143767  21418.80338032  11195.11720641  -7422.69311699\n -12321.67975483  -8939.5485368   -8210.78606852 -11295.29291854\n -13345.99426694 -12252.29409188 -10536.15667672 -15563.16303962\n -11662.99590443 -15645.54161528 -17923.26834686 -16892.15799757\n -18604.61384286 -16815.81240033 -16202.42632031 -19225.58971046\n -15180.76427714 -12206.07816018 -13613.3174655  -12621.75136617].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "output = [lda.predict(test) for test in test_pca]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizer(x):\n",
    "    \"\"\"divides the feature space by perceived arousal level of emotion (high/low)\"\"\"\n",
    "    if x in ['HAPPY', 'FEAR', 'ANGER', 'SURPRISE','HIGH VALENCE', 'HIGH ENERGY','HIGH TENSION']:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = [4,8,12,30,45] #4 bands\n",
    "window_size = 2000 #Averaging band power of 2 sec\n",
    "step_size = 125 #1/8 second step\n",
    "sample_rate = 1000 #Each 0.125 sec update once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(finalHeaderNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              FP1        FP2         F7         F3         Fz         F4  \\\n0     -232.628543 -84.023245  57.974299  -3.002626   8.304956 -12.351710   \n1     -232.815737 -84.354865  58.570296  -2.830203   9.961316 -13.989259   \n2     -233.876498 -83.967975  59.357012  -1.623242  11.123769 -12.522584   \n3     -238.306737 -87.947411  57.235262  -2.334487   7.928387 -14.345248   \n4     -241.738612 -89.329159  53.254002  -4.317351   9.344615 -11.981481   \n...           ...        ...        ...        ...        ...        ...   \n15995  -62.781916  39.394522  75.735013  10.489473   4.733005  13.464603   \n15996  -67.524143  35.857246  72.492789  11.761092   3.136678  11.656180   \n15997  -61.908347  33.646449  77.642204  14.541413   3.133949  10.303422   \n15998  -59.974018  35.249277  75.210535  13.291346   3.338606  11.627701   \n15999  -61.284370  34.862387  70.347199  11.071400   2.580010   9.463289   \n\n              F8         T3         C3         Cz         C4          T4  \\\n0      -4.564134  34.721616  34.305990 -80.553639  64.547816   86.102119   \n1      -4.108805  36.077969  35.701170 -81.918580  61.791627   80.731111   \n2      -4.741206  34.107688  33.914659 -81.758782  64.165934   82.015482   \n3      -7.979102  31.637698  30.035379 -81.308240  64.348573   81.948762   \n4      -6.638411  28.382451  28.180810 -82.890684  64.796869   82.265685   \n...          ...        ...        ...        ...        ...         ...   \n15995   6.970870  63.362076  15.879407 -60.239325  85.634323  111.939673   \n15996   1.608105  63.219302  15.045701 -58.810022  95.197968  105.768017   \n15997   7.046758  62.733871  15.130773 -59.826514  75.240501  106.418543   \n15998  11.271200  63.205025  14.552284 -59.571281  58.670159   87.636693   \n15999   6.136100  60.021165  12.476529 -60.046236  73.148454   53.459064   \n\n              T5         P3         Pz         P4        T6          O1  \\\n0      55.599693  15.165444  12.035700  14.351771 -1.056958  105.074995   \n1      62.401470  22.186849  11.466394  11.677751 -5.855176   82.731737   \n2      53.146194  16.514599  10.129388  13.594973 -3.975874   97.409108   \n3      50.716988   3.124606   9.538518  13.815705 -0.737076  130.383109   \n4      54.725179  -3.214968   9.240926  14.831076  0.862330  138.422942   \n...          ...        ...        ...        ...       ...         ...   \n15995  73.867323  14.055656  24.849395  22.676549  2.381766  104.474011   \n15996  69.543336  12.633967  24.965844  22.354910  3.261439  102.350533   \n15997  67.235591  12.423615  23.732348  18.697053  0.262552   99.799689   \n15998  67.235591  10.443405  24.193830  18.312347  5.580578  102.630993   \n15999  62.692975   6.635308  21.286920  18.772732  2.181840   97.529304   \n\n               O2  \n0      101.596801  \n1       96.587040  \n2       95.214997  \n3      100.757328  \n4      103.384067  \n...           ...  \n15995   89.582401  \n15996   86.549464  \n15997   82.947852  \n15998   87.488230  \n15999   83.841485  \n\n[16000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1171\n",
      "Done with  1\n",
      "Done with  2\n",
      "Done with  3\n",
      "Done with  4\n",
      "Done with  5\n",
      "Done with  6\n",
      "Done with  7\n",
      "Done with  8\n",
      "Done with  9\n",
      "Done with  10\n",
      "Done with  11\n",
      "Done with  12\n",
      "Done with  13\n",
      "Done with  14\n",
      "Done with  15\n",
      "Done with  16\n",
      "Done with  17\n",
      "Done with  18\n",
      "Done with  19\n",
      "Done with  20\n",
      "Done with  21\n",
      "Done with  22\n",
      "Done with  23\n",
      "Done with  24\n",
      "Done with  25\n",
      "Done with  26\n",
      "Done with  27\n",
      "Done with  28\n",
      "Done with  29\n",
      "Done with  30\n",
      "Done with  31\n",
      "Done with  32\n",
      "Done with  33\n",
      "Done with  34\n",
      "Done with  35\n",
      "Done with  36\n",
      "Done with  37\n",
      "Done with  38\n",
      "Done with  39\n",
      "Done with  40\n",
      "Done with  41\n",
      "Done with  42\n",
      "Done with  43\n",
      "Done with  44\n",
      "Done with  45\n",
      "Done with  46\n",
      "Done with  47\n",
      "Done with  48\n",
      "Done with  49\n",
      "Done with  50\n",
      "Done with  51\n",
      "Done with  52\n",
      "Done with  53\n",
      "Done with  54\n",
      "Done with  55\n",
      "Done with  56\n",
      "Done with  57\n",
      "Done with  58\n",
      "Done with  59\n",
      "Done with  60\n",
      "Done with  61\n",
      "Done with  62\n",
      "Done with  63\n",
      "Done with  64\n",
      "Done with  65\n",
      "Done with  66\n",
      "Done with  67\n",
      "Done with  68\n",
      "Done with  69\n",
      "Done with  70\n",
      "Done with  71\n",
      "Done with  72\n",
      "Done with  73\n",
      "Done with  74\n",
      "Done with  75\n",
      "Done with  76\n",
      "Done with  77\n",
      "Done with  78\n",
      "Done with  79\n",
      "Done with  80\n",
      "Done with  81\n",
      "Done with  82\n",
      "Done with  83\n",
      "Done with  84\n",
      "Done with  85\n",
      "Done with  86\n",
      "Done with  87\n",
      "Done with  88\n",
      "Done with  89\n",
      "Done with  90\n",
      "Done with  91\n",
      "Done with  92\n",
      "Done with  93\n",
      "Done with  94\n",
      "Done with  95\n",
      "Done with  96\n",
      "Done with  97\n",
      "Done with  98\n",
      "Done with  99\n",
      "Done with  100\n",
      "Done with  101\n",
      "Done with  102\n",
      "Done with  103\n",
      "Done with  104\n",
      "Done with  105\n",
      "Done with  106\n",
      "Done with  107\n",
      "Done with  108\n",
      "Done with  109\n",
      "Done with  110\n",
      "Done with  111\n",
      "Done with  112\n",
      "Done with  113\n",
      "Done with  114\n",
      "Done with  115\n",
      "Done with  116\n",
      "Done with  117\n",
      "Done with  118\n",
      "Done with  119\n",
      "Done with  120\n",
      "Done with  121\n",
      "Done with  122\n",
      "Done with  123\n",
      "Done with  124\n",
      "Done with  125\n",
      "Done with  126\n",
      "Done with  127\n",
      "Done with  128\n",
      "Done with  129\n",
      "Done with  130\n",
      "Done with  131\n",
      "Done with  132\n",
      "Done with  133\n",
      "Done with  134\n",
      "Done with  135\n",
      "Done with  136\n",
      "Done with  137\n",
      "Done with  138\n",
      "Done with  139\n",
      "Done with  140\n",
      "Done with  141\n",
      "Done with  142\n",
      "Done with  143\n",
      "Done with  144\n",
      "Done with  145\n",
      "Done with  146\n",
      "Done with  147\n",
      "Done with  148\n",
      "Done with  149\n",
      "Done with  150\n",
      "Done with  151\n",
      "Done with  152\n",
      "Done with  153\n",
      "Done with  154\n",
      "Done with  155\n",
      "Done with  156\n",
      "Done with  157\n",
      "Done with  158\n",
      "Done with  159\n",
      "Done with  160\n",
      "Done with  161\n",
      "Done with  162\n",
      "Done with  163\n",
      "Done with  164\n",
      "Done with  165\n",
      "Done with  166\n",
      "Done with  167\n",
      "Done with  168\n",
      "Done with  169\n",
      "Done with  170\n",
      "Done with  171\n",
      "Done with  172\n",
      "Done with  173\n",
      "Done with  174\n",
      "Done with  175\n",
      "Done with  176\n",
      "Done with  177\n",
      "Done with  178\n",
      "Done with  179\n",
      "Done with  180\n",
      "Done with  181\n",
      "Done with  182\n",
      "Done with  183\n",
      "Done with  184\n",
      "Done with  185\n",
      "Done with  186\n",
      "Done with  187\n",
      "Done with  188\n",
      "Done with  189\n",
      "Done with  190\n",
      "Done with  191\n",
      "Done with  192\n",
      "Done with  193\n",
      "Done with  194\n",
      "Done with  195\n",
      "Done with  196\n",
      "Done with  197\n",
      "Done with  198\n",
      "Done with  199\n",
      "Done with  200\n",
      "Done with  201\n",
      "Done with  202\n",
      "Done with  203\n",
      "Done with  204\n",
      "Done with  205\n",
      "Done with  206\n",
      "Done with  207\n",
      "Done with  208\n",
      "Done with  209\n",
      "Done with  210\n",
      "Done with  211\n",
      "Done with  212\n",
      "Done with  213\n",
      "Done with  214\n",
      "Done with  215\n",
      "Done with  216\n",
      "Done with  217\n",
      "Done with  218\n",
      "Done with  219\n",
      "Done with  220\n",
      "Done with  221\n",
      "Done with  222\n",
      "Done with  223\n",
      "Done with  224\n",
      "Done with  225\n",
      "Done with  226\n",
      "Done with  227\n",
      "Done with  228\n",
      "Done with  229\n",
      "Done with  230\n",
      "Done with  231\n",
      "Done with  232\n",
      "Done with  233\n",
      "Done with  234\n",
      "Done with  235\n",
      "Done with  236\n",
      "Done with  237\n",
      "Done with  238\n",
      "Done with  239\n",
      "Done with  240\n",
      "Done with  241\n",
      "Done with  242\n",
      "Done with  243\n",
      "Done with  244\n",
      "Done with  245\n",
      "Done with  246\n",
      "Done with  247\n",
      "Done with  248\n",
      "Done with  249\n",
      "Done with  250\n",
      "Done with  251\n",
      "Done with  252\n",
      "Done with  253\n",
      "Done with  254\n",
      "Done with  255\n",
      "Done with  256\n",
      "Done with  257\n",
      "Done with  258\n",
      "Done with  259\n",
      "Done with  260\n",
      "Done with  261\n",
      "Done with  262\n",
      "Done with  263\n",
      "Done with  264\n",
      "Done with  265\n",
      "Done with  266\n",
      "Done with  267\n",
      "Done with  268\n",
      "Done with  269\n",
      "Done with  270\n",
      "Done with  271\n",
      "Done with  272\n",
      "Done with  273\n",
      "Done with  274\n",
      "Done with  275\n",
      "Done with  276\n",
      "Done with  277\n",
      "Done with  278\n",
      "Done with  279\n",
      "Done with  280\n",
      "Done with  281\n",
      "Done with  282\n",
      "Done with  283\n",
      "Done with  284\n",
      "Done with  285\n",
      "Done with  286\n",
      "Done with  287\n",
      "Done with  288\n",
      "Done with  289\n",
      "Done with  290\n",
      "Done with  291\n",
      "Done with  292\n",
      "Done with  293\n",
      "Done with  294\n",
      "Done with  295\n",
      "Done with  296\n",
      "Done with  297\n",
      "Done with  298\n",
      "Done with  299\n",
      "Done with  300\n",
      "Done with  301\n",
      "Done with  302\n",
      "Done with  303\n",
      "Done with  304\n",
      "Done with  305\n",
      "Done with  306\n",
      "Done with  307\n",
      "Done with  308\n",
      "Done with  309\n",
      "Done with  310\n",
      "Done with  311\n",
      "Done with  312\n",
      "Done with  313\n",
      "Done with  314\n",
      "Done with  315\n",
      "Done with  316\n",
      "Done with  317\n",
      "Done with  318\n",
      "Done with  319\n",
      "Done with  320\n",
      "Done with  321\n",
      "Done with  322\n",
      "Done with  323\n",
      "Done with  324\n",
      "Done with  325\n",
      "Done with  326\n",
      "Done with  327\n",
      "Done with  328\n",
      "Done with  329\n",
      "Done with  330\n",
      "Done with  331\n",
      "Done with  332\n",
      "Done with  333\n",
      "Done with  334\n",
      "Done with  335\n",
      "Done with  336\n",
      "Done with  337\n",
      "Done with  338\n",
      "Done with  339\n",
      "Done with  340\n",
      "Done with  341\n",
      "Done with  342\n",
      "Done with  343\n",
      "Done with  344\n",
      "Done with  345\n",
      "Done with  346\n",
      "Done with  347\n",
      "Done with  348\n",
      "Done with  349\n",
      "Done with  350\n",
      "Done with  351\n",
      "Done with  352\n",
      "Done with  353\n",
      "Done with  354\n",
      "Done with  355\n",
      "Done with  356\n",
      "Done with  357\n",
      "Done with  358\n",
      "Done with  359\n",
      "Done with  360\n",
      "Done with  361\n",
      "Done with  362\n",
      "Done with  363\n",
      "Done with  364\n",
      "Done with  365\n",
      "Done with  366\n",
      "Done with  367\n",
      "Done with  368\n",
      "Done with  369\n",
      "Done with  370\n",
      "Done with  371\n",
      "Done with  372\n",
      "Done with  373\n",
      "Done with  374\n",
      "Done with  375\n",
      "Done with  376\n",
      "Done with  377\n",
      "Done with  378\n",
      "Done with  379\n",
      "Done with  380\n",
      "Done with  381\n",
      "Done with  382\n",
      "Done with  383\n",
      "Done with  384\n",
      "Done with  385\n",
      "Done with  386\n",
      "Done with  387\n",
      "Done with  388\n",
      "Done with  389\n",
      "Done with  390\n",
      "Done with  391\n",
      "Done with  392\n",
      "Done with  393\n",
      "Done with  394\n",
      "Done with  395\n",
      "Done with  396\n",
      "Done with  397\n",
      "Done with  398\n",
      "Done with  399\n",
      "Done with  400\n",
      "Done with  401\n",
      "Done with  402\n",
      "Done with  403\n",
      "Done with  404\n",
      "Done with  405\n",
      "Done with  406\n",
      "Done with  407\n",
      "Done with  408\n",
      "Done with  409\n",
      "Done with  410\n",
      "Done with  411\n",
      "Done with  412\n",
      "Done with  413\n",
      "Done with  414\n",
      "Done with  415\n",
      "Done with  416\n",
      "Done with  417\n",
      "Done with  418\n",
      "Done with  419\n",
      "Done with  420\n",
      "Done with  421\n",
      "Done with  422\n",
      "Done with  423\n",
      "Done with  424\n",
      "Done with  425\n",
      "Done with  426\n",
      "Done with  427\n",
      "Done with  428\n",
      "Done with  429\n",
      "Done with  430\n",
      "Done with  431\n",
      "Done with  432\n",
      "Done with  433\n",
      "Done with  434\n",
      "Done with  435\n",
      "Done with  436\n",
      "Done with  437\n",
      "Done with  438\n",
      "Done with  439\n",
      "Done with  440\n",
      "Done with  441\n",
      "Done with  442\n",
      "Done with  443\n",
      "Done with  444\n",
      "Done with  445\n",
      "Done with  446\n",
      "Done with  447\n",
      "Done with  448\n",
      "Done with  449\n",
      "Done with  450\n",
      "Done with  451\n",
      "Done with  452\n",
      "Done with  453\n",
      "Done with  454\n",
      "Done with  455\n",
      "Done with  456\n",
      "Done with  457\n",
      "Done with  458\n",
      "Done with  459\n",
      "Done with  460\n",
      "Done with  461\n",
      "Done with  462\n",
      "Done with  463\n",
      "Done with  464\n",
      "Done with  465\n",
      "Done with  466\n",
      "Done with  467\n",
      "Done with  468\n",
      "Done with  469\n",
      "Done with  470\n",
      "Done with  471\n",
      "Done with  472\n",
      "Done with  473\n",
      "Done with  474\n",
      "Done with  475\n",
      "Done with  476\n",
      "Done with  477\n",
      "Done with  478\n",
      "Done with  479\n",
      "Done with  480\n",
      "Done with  481\n",
      "Done with  482\n",
      "Done with  483\n",
      "Done with  484\n",
      "Done with  485\n",
      "Done with  486\n",
      "Done with  487\n",
      "Done with  488\n",
      "Done with  489\n",
      "Done with  490\n",
      "Done with  491\n",
      "Done with  492\n",
      "Done with  493\n",
      "Done with  494\n",
      "Done with  495\n",
      "Done with  496\n",
      "Done with  497\n",
      "Done with  498\n",
      "Done with  499\n",
      "Done with  500\n",
      "Done with  501\n",
      "Done with  502\n",
      "Done with  503\n",
      "Done with  504\n",
      "Done with  505\n",
      "Done with  506\n",
      "Done with  507\n",
      "Done with  508\n",
      "Done with  509\n",
      "Done with  510\n",
      "Done with  511\n",
      "Done with  512\n",
      "Done with  513\n",
      "Done with  514\n",
      "Done with  515\n",
      "Done with  516\n",
      "Done with  517\n",
      "Done with  518\n",
      "Done with  519\n",
      "Done with  520\n",
      "Done with  521\n",
      "Done with  522\n",
      "Done with  523\n",
      "Done with  524\n",
      "Done with  525\n",
      "Done with  526\n",
      "Done with  527\n",
      "Done with  528\n",
      "Done with  529\n",
      "Done with  530\n",
      "Done with  531\n",
      "Done with  532\n",
      "Done with  533\n",
      "Done with  534\n",
      "Done with  535\n",
      "Done with  536\n",
      "Done with  537\n",
      "Done with  538\n",
      "Done with  539\n",
      "Done with  540\n",
      "Done with  541\n",
      "Done with  542\n",
      "Done with  543\n",
      "Done with  544\n",
      "Done with  545\n",
      "Done with  546\n",
      "Done with  547\n",
      "Done with  548\n",
      "Done with  549\n",
      "Done with  550\n",
      "Done with  551\n",
      "Done with  552\n",
      "Done with  553\n",
      "Done with  554\n",
      "Done with  555\n",
      "Done with  556\n",
      "Done with  557\n",
      "Done with  558\n",
      "Done with  559\n",
      "Done with  560\n",
      "Done with  561\n",
      "Done with  562\n",
      "Done with  563\n",
      "Done with  564\n",
      "Done with  565\n",
      "Done with  566\n",
      "Done with  567\n",
      "Done with  568\n",
      "Done with  569\n",
      "Done with  570\n",
      "Done with  571\n",
      "Done with  572\n",
      "Done with  573\n",
      "Done with  574\n",
      "Done with  575\n",
      "Done with  576\n",
      "Done with  577\n",
      "Done with  578\n",
      "Done with  579\n",
      "Done with  580\n",
      "Done with  581\n",
      "Done with  582\n",
      "Done with  583\n",
      "Done with  584\n",
      "Done with  585\n",
      "Done with  586\n",
      "Done with  587\n",
      "Done with  588\n",
      "Done with  589\n",
      "Done with  590\n",
      "Done with  591\n",
      "Done with  592\n",
      "Done with  593\n",
      "Done with  594\n",
      "Done with  595\n",
      "Done with  596\n",
      "Done with  597\n",
      "Done with  598\n",
      "Done with  599\n",
      "Done with  600\n",
      "Done with  601\n",
      "Done with  602\n",
      "Done with  603\n",
      "Done with  604\n",
      "Done with  605\n",
      "Done with  606\n",
      "Done with  607\n",
      "Done with  608\n",
      "Done with  609\n",
      "Done with  610\n",
      "Done with  611\n",
      "Done with  612\n",
      "Done with  613\n",
      "Done with  614\n",
      "Done with  615\n",
      "Done with  616\n",
      "Done with  617\n",
      "Done with  618\n",
      "Done with  619\n",
      "Done with  620\n",
      "Done with  621\n",
      "Done with  622\n",
      "Done with  623\n",
      "Done with  624\n",
      "Done with  625\n",
      "Done with  626\n",
      "Done with  627\n",
      "Done with  628\n",
      "Done with  629\n",
      "Done with  630\n",
      "Done with  631\n",
      "Done with  632\n",
      "Done with  633\n",
      "Done with  634\n",
      "Done with  635\n",
      "Done with  636\n",
      "Done with  637\n",
      "Done with  638\n",
      "Done with  639\n",
      "Done with  640\n",
      "Done with  641\n",
      "Done with  642\n",
      "Done with  643\n",
      "Done with  644\n",
      "Done with  645\n",
      "Done with  646\n",
      "Done with  647\n",
      "Done with  648\n",
      "Done with  649\n",
      "Done with  650\n",
      "Done with  651\n",
      "Done with  652\n",
      "Done with  653\n",
      "Done with  654\n",
      "Done with  655\n",
      "Done with  656\n",
      "Done with  657\n",
      "Done with  658\n",
      "Done with  659\n",
      "Done with  660\n",
      "Done with  661\n",
      "Done with  662\n",
      "Done with  663\n",
      "Done with  664\n",
      "Done with  665\n",
      "Done with  666\n",
      "Done with  667\n",
      "Done with  668\n",
      "Done with  669\n",
      "Done with  670\n",
      "Done with  671\n",
      "Done with  672\n",
      "Done with  673\n",
      "Done with  674\n",
      "Done with  675\n",
      "Done with  676\n",
      "Done with  677\n",
      "Done with  678\n",
      "Done with  679\n",
      "Done with  680\n",
      "Done with  681\n",
      "Done with  682\n",
      "Done with  683\n",
      "Done with  684\n",
      "Done with  685\n",
      "Done with  686\n",
      "Done with  687\n",
      "Done with  688\n",
      "Done with  689\n",
      "Done with  690\n",
      "Done with  691\n",
      "Done with  692\n",
      "Done with  693\n",
      "Done with  694\n",
      "Done with  695\n",
      "Done with  696\n",
      "Done with  697\n",
      "Done with  698\n",
      "Done with  699\n",
      "Done with  700\n",
      "Done with  701\n",
      "Done with  702\n",
      "Done with  703\n",
      "Done with  704\n",
      "Done with  705\n",
      "Done with  706\n",
      "Done with  707\n",
      "Done with  708\n",
      "Done with  709\n",
      "Done with  710\n",
      "Done with  711\n",
      "Done with  712\n",
      "Done with  713\n",
      "Done with  714\n",
      "Done with  715\n",
      "Done with  716\n",
      "Done with  717\n",
      "Done with  718\n",
      "Done with  719\n",
      "Done with  720\n",
      "Done with  721\n",
      "Done with  722\n",
      "Done with  723\n",
      "Done with  724\n",
      "Done with  725\n",
      "Done with  726\n",
      "Done with  727\n",
      "Done with  728\n",
      "Done with  729\n",
      "Done with  730\n",
      "Done with  731\n",
      "Done with  732\n",
      "Done with  733\n",
      "Done with  734\n",
      "Done with  735\n",
      "Done with  736\n",
      "Done with  737\n",
      "Done with  738\n",
      "Done with  739\n",
      "Done with  740\n",
      "Done with  741\n",
      "Done with  742\n",
      "Done with  743\n",
      "Done with  744\n",
      "Done with  745\n",
      "Done with  746\n",
      "Done with  747\n",
      "Done with  748\n",
      "Done with  749\n",
      "Done with  750\n",
      "Done with  751\n",
      "Done with  752\n",
      "Done with  753\n",
      "Done with  754\n",
      "Done with  755\n",
      "Done with  756\n",
      "Done with  757\n",
      "Done with  758\n",
      "Done with  759\n",
      "Done with  760\n",
      "Done with  761\n",
      "Done with  762\n",
      "Done with  763\n",
      "Done with  764\n",
      "Done with  765\n",
      "Done with  766\n",
      "Done with  767\n",
      "Done with  768\n",
      "Done with  769\n",
      "Done with  770\n",
      "Done with  771\n",
      "Done with  772\n",
      "Done with  773\n",
      "Done with  774\n",
      "Done with  775\n",
      "Done with  776\n",
      "Done with  777\n",
      "Done with  778\n",
      "Done with  779\n",
      "Done with  780\n",
      "Done with  781\n",
      "Done with  782\n",
      "Done with  783\n",
      "Done with  784\n",
      "Done with  785\n",
      "Done with  786\n",
      "Done with  787\n",
      "Done with  788\n",
      "Done with  789\n",
      "Done with  790\n",
      "Done with  791\n",
      "Done with  792\n",
      "Done with  793\n",
      "Done with  794\n",
      "Done with  795\n",
      "Done with  796\n",
      "Done with  797\n",
      "Done with  798\n",
      "Done with  799\n",
      "Done with  800\n",
      "Done with  801\n",
      "Done with  802\n",
      "Done with  803\n",
      "Done with  804\n",
      "Done with  805\n",
      "Done with  806\n",
      "Done with  807\n",
      "Done with  808\n",
      "Done with  809\n",
      "Done with  810\n",
      "Done with  811\n",
      "Done with  812\n",
      "Done with  813\n",
      "Done with  814\n",
      "Done with  815\n",
      "Done with  816\n",
      "Done with  817\n",
      "Done with  818\n",
      "Done with  819\n",
      "Done with  820\n",
      "Done with  821\n",
      "Done with  822\n",
      "Done with  823\n",
      "Done with  824\n",
      "Done with  825\n",
      "Done with  826\n",
      "Done with  827\n",
      "Done with  828\n",
      "Done with  829\n",
      "Done with  830\n",
      "Done with  831\n",
      "Done with  832\n",
      "Done with  833\n",
      "Done with  834\n",
      "Done with  835\n",
      "Done with  836\n",
      "Done with  837\n",
      "Done with  838\n",
      "Done with  839\n",
      "Done with  840\n",
      "Done with  841\n",
      "Done with  842\n",
      "Done with  843\n",
      "Done with  844\n",
      "Done with  845\n",
      "Done with  846\n",
      "Done with  847\n",
      "Done with  848\n",
      "Done with  849\n",
      "Done with  850\n",
      "Done with  851\n",
      "Done with  852\n",
      "Done with  853\n",
      "Done with  854\n",
      "Done with  855\n",
      "Done with  856\n",
      "Done with  857\n",
      "Done with  858\n",
      "Done with  859\n",
      "Done with  860\n",
      "Done with  861\n",
      "Done with  862\n",
      "Done with  863\n",
      "Done with  864\n",
      "Done with  865\n",
      "Done with  866\n",
      "Done with  867\n",
      "Done with  868\n",
      "Done with  869\n",
      "Done with  870\n",
      "Done with  871\n",
      "Done with  872\n",
      "Done with  873\n",
      "Done with  874\n",
      "Done with  875\n",
      "Done with  876\n",
      "Done with  877\n",
      "Done with  878\n",
      "Done with  879\n",
      "Done with  880\n",
      "Done with  881\n",
      "Done with  882\n",
      "Done with  883\n",
      "Done with  884\n",
      "Done with  885\n",
      "Done with  886\n",
      "Done with  887\n",
      "Done with  888\n",
      "Done with  889\n",
      "Done with  890\n",
      "Done with  891\n",
      "Done with  892\n",
      "Done with  893\n",
      "Done with  894\n",
      "Done with  895\n",
      "Done with  896\n",
      "Done with  897\n",
      "Done with  898\n",
      "Done with  899\n",
      "Done with  900\n",
      "Done with  901\n",
      "Done with  902\n",
      "Done with  903\n",
      "Done with  904\n",
      "Done with  905\n",
      "Done with  906\n",
      "Done with  907\n",
      "Done with  908\n",
      "Done with  909\n",
      "Done with  910\n",
      "Done with  911\n",
      "Done with  912\n",
      "Done with  913\n",
      "Done with  914\n",
      "Done with  915\n",
      "Done with  916\n",
      "Done with  917\n",
      "Done with  918\n",
      "Done with  919\n",
      "Done with  920\n",
      "Done with  921\n",
      "Done with  922\n",
      "Done with  923\n",
      "Done with  924\n",
      "Done with  925\n",
      "Done with  926\n",
      "Done with  927\n",
      "Done with  928\n",
      "Done with  929\n",
      "Done with  930\n",
      "Done with  931\n",
      "Done with  932\n",
      "Done with  933\n",
      "Done with  934\n",
      "Done with  935\n",
      "Done with  936\n",
      "Done with  937\n",
      "Done with  938\n",
      "Done with  939\n",
      "Done with  940\n",
      "Done with  941\n",
      "Done with  942\n",
      "Done with  943\n",
      "Done with  944\n",
      "Done with  945\n",
      "Done with  946\n",
      "Done with  947\n",
      "Done with  948\n",
      "Done with  949\n",
      "Done with  950\n",
      "Done with  951\n",
      "Done with  952\n",
      "Done with  953\n",
      "Done with  954\n",
      "Done with  955\n",
      "Done with  956\n",
      "Done with  957\n",
      "Done with  958\n",
      "Done with  959\n",
      "Done with  960\n",
      "Done with  961\n",
      "Done with  962\n",
      "Done with  963\n",
      "Done with  964\n",
      "Done with  965\n",
      "Done with  966\n",
      "Done with  967\n",
      "Done with  968\n",
      "Done with  969\n",
      "Done with  970\n",
      "Done with  971\n",
      "Done with  972\n",
      "Done with  973\n",
      "Done with  974\n",
      "Done with  975\n",
      "Done with  976\n",
      "Done with  977\n",
      "Done with  978\n",
      "Done with  979\n",
      "Done with  980\n",
      "Done with  981\n",
      "Done with  982\n",
      "Done with  983\n",
      "Done with  984\n",
      "Done with  985\n",
      "Done with  986\n",
      "Done with  987\n",
      "Done with  988\n",
      "Done with  989\n",
      "Done with  990\n",
      "Done with  991\n",
      "Done with  992\n",
      "Done with  993\n",
      "Done with  994\n",
      "Done with  995\n",
      "Done with  996\n",
      "Done with  997\n",
      "Done with  998\n",
      "Done with  999\n",
      "Done with  1000\n",
      "Done with  1001\n",
      "Done with  1002\n",
      "Done with  1003\n",
      "Done with  1004\n",
      "Done with  1005\n",
      "Done with  1006\n",
      "Done with  1007\n",
      "Done with  1008\n",
      "Done with  1009\n",
      "Done with  1010\n",
      "Done with  1011\n",
      "Done with  1012\n",
      "Done with  1013\n",
      "Done with  1014\n",
      "Done with  1015\n",
      "Done with  1016\n",
      "Done with  1017\n",
      "Done with  1018\n",
      "Done with  1019\n",
      "Done with  1020\n",
      "Done with  1021\n",
      "Done with  1022\n",
      "Done with  1023\n",
      "Done with  1024\n",
      "Done with  1025\n",
      "Done with  1026\n",
      "Done with  1027\n",
      "Done with  1028\n",
      "Done with  1029\n",
      "Done with  1030\n",
      "Done with  1031\n",
      "Done with  1032\n",
      "Done with  1033\n",
      "Done with  1034\n",
      "Done with  1035\n",
      "Done with  1036\n",
      "Done with  1037\n",
      "Done with  1038\n",
      "Done with  1039\n",
      "Done with  1040\n",
      "Done with  1041\n",
      "Done with  1042\n",
      "Done with  1043\n",
      "Done with  1044\n",
      "Done with  1045\n",
      "Done with  1046\n",
      "Done with  1047\n",
      "Done with  1048\n",
      "Done with  1049\n",
      "Done with  1050\n",
      "Done with  1051\n",
      "Done with  1052\n",
      "Done with  1053\n",
      "Done with  1054\n",
      "Done with  1055\n",
      "Done with  1056\n",
      "Done with  1057\n",
      "Done with  1058\n",
      "Done with  1059\n",
      "Done with  1060\n",
      "Done with  1061\n",
      "Done with  1062\n",
      "Done with  1063\n",
      "Done with  1064\n",
      "Done with  1065\n",
      "Done with  1066\n",
      "Done with  1067\n",
      "Done with  1068\n",
      "Done with  1069\n",
      "Done with  1070\n",
      "Done with  1071\n",
      "Done with  1072\n",
      "Done with  1073\n",
      "Done with  1074\n",
      "Done with  1075\n",
      "Done with  1076\n",
      "Done with  1077\n",
      "Done with  1078\n",
      "Done with  1079\n",
      "Done with  1080\n",
      "Done with  1081\n",
      "Done with  1082\n",
      "Done with  1083\n",
      "Done with  1084\n",
      "Done with  1085\n",
      "Done with  1086\n",
      "Done with  1087\n",
      "Done with  1088\n",
      "Done with  1089\n",
      "Done with  1090\n",
      "Done with  1091\n",
      "Done with  1092\n",
      "Done with  1093\n",
      "Done with  1094\n",
      "Done with  1095\n",
      "Done with  1096\n",
      "Done with  1097\n",
      "Done with  1098\n",
      "Done with  1099\n",
      "Done with  1100\n",
      "Done with  1101\n",
      "Done with  1102\n",
      "Done with  1103\n",
      "Done with  1104\n",
      "Done with  1105\n",
      "Done with  1106\n",
      "Done with  1107\n",
      "Done with  1108\n",
      "Done with  1109\n",
      "Done with  1110\n",
      "Done with  1111\n",
      "Done with  1112\n",
      "Done with  1113\n",
      "Done with  1114\n",
      "Done with  1115\n",
      "Done with  1116\n",
      "Done with  1117\n",
      "Done with  1118\n",
      "Done with  1119\n",
      "Done with  1120\n",
      "Done with  1121\n",
      "Done with  1122\n",
      "Done with  1123\n",
      "Done with  1124\n",
      "Done with  1125\n",
      "Done with  1126\n",
      "Done with  1127\n",
      "Done with  1128\n",
      "Done with  1129\n",
      "Done with  1130\n",
      "Done with  1131\n",
      "Done with  1132\n",
      "Done with  1133\n",
      "Done with  1134\n",
      "Done with  1135\n",
      "Done with  1136\n",
      "Done with  1137\n",
      "Done with  1138\n",
      "Done with  1139\n",
      "Done with  1140\n",
      "Done with  1141\n",
      "Done with  1142\n",
      "Done with  1143\n",
      "Done with  1144\n",
      "Done with  1145\n",
      "Done with  1146\n",
      "Done with  1147\n",
      "Done with  1148\n",
      "Done with  1149\n",
      "Done with  1150\n",
      "Done with  1151\n",
      "Done with  1152\n",
      "Done with  1153\n",
      "Done with  1154\n",
      "Done with  1155\n",
      "Done with  1156\n",
      "Done with  1157\n",
      "Done with  1158\n",
      "Done with  1159\n",
      "Done with  1160\n",
      "Done with  1161\n",
      "Done with  1162\n",
      "Done with  1163\n",
      "Done with  1164\n",
      "Done with  1165\n",
      "Done with  1166\n",
      "Done with  1167\n",
      "Done with  1168\n",
      "Done with  1169\n",
      "Done with  1170\n",
      "Done with  1171\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "fft_data = []\n",
    "print\n",
    "count = 0\n",
    "for trainingDF in train_data:\n",
    "    fft_data.append(FFT_Processing(trainingDF))\n",
    "    count = count + 1\n",
    "    print(\"Done with \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "fft_np = np.array(fft_data[0])\n",
    "apca = pca.fit(fft_np, train_labels).transform(fft_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "38\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "print(len(test_labels))\n",
    "apca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [112, 1171]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-5ba0de18808e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m--> 424\u001b[1;33m         X, y = self._validate_data(X, y, ensure_min_samples=2, estimator=self,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                    dtype=[np.float64, np.float32])\n\u001b[0;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [112, 1171]"
     ]
    }
   ],
   "source": []
  },
  {
   "source": [
    "apply a fourier transform to the data in discrete sections so that you can get the average levels of each "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [77, 1171]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-53244f0ab732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfft_resize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfft_resize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Percentage of variance explained for each components\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m print('explained variance ratio (first two components): %s'\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m--> 424\u001b[1;33m         X, y = self._validate_data(X, y, ensure_min_samples=2, estimator=self,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                    dtype=[np.float64, np.float32])\n\u001b[0;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [77, 1171]"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_r2 = lda.fit(fft_resize, train_labels).transform(fft_resize)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(apca[y == i, 0], apca[train_labels == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of IRIS dataset')\n",
    "\n",
    "plt.figure()\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r2[y == i, 0], X_r2[y == i, 1], alpha=.8, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate target and non-target for plotting\n",
    "tar     = train_data[np.where(pd.Series(train_labels).apply(binarizer).to_numpy() == 1)[0], :, :]\n",
    "non_tar = train_data[np.where(pd.Series(train_labels).apply(binarizer).to_numpy() == 0)[0], :, :]\n",
    "\n",
    "print('We have %d target trials' % tar.shape[0])\n",
    "print('We have %d non-target trials' % non_tar.shape[0])\n",
    "\n",
    "# We'll take the average of all trials to create an averaged ERP\n",
    "tar_avg     = np.mean(tar, 0)\n",
    "non_tar_avg = np.mean(non_tar, 0)\n",
    "\n",
    "# Define channel of interest and create an array of time points\n",
    "chan = 'Cz' # let's plot Cz\n",
    "ch = np.where(channels == chan)[0][0]\n",
    "times = np.linspace(epoch_start, epoch_end, train_data.shape[1])\n",
    "\n",
    "# Initialize plot and calculate min and max y value\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 6))\n",
    "min_y = min(np.min(tar_avg), np.min(non_tar_avg))\n",
    "max_y = max(np.max(tar_avg), np.max(non_tar_avg))\n",
    "\n",
    "# Plot x and y axes\n",
    "plt.plot([np.min(times), np.max(times)], [0, 0], color='k');  # x-axis\n",
    "plt.plot([0, 0], [min_y, max_y], color='k');                  # y-axis\n",
    "\n",
    "# Plot our averaged ERPs\n",
    "plt.plot(times, tar_avg[:, ch], 'b', linewidth=4)\n",
    "plt.plot(times, non_tar_avg[:, ch], 'r', linewidth=4)\n",
    "\n",
    "# Highlight the baseline window and window of interest of our ERP\n",
    "baseline = patches.Rectangle([baseline_start, min_y], baseline_end, np.abs(min_y)+max_y, \n",
    "                             color='c', alpha=0.2)\n",
    "erp_win = patches.Rectangle([erp_start, min_y], erp_end-erp_start, np.abs(min_y)+max_y, \n",
    "                             color='lime', alpha=0.3)\n",
    "\n",
    "# Add our baseline and window of interest highlights\n",
    "ax.add_patch(baseline)\n",
    "ax.add_patch(erp_win)\n",
    "\n",
    "# Manually create legends since patches will corrupt default handles\n",
    "legend_ = [patches.Patch(color='b', label = 'Target (oddball)'),\n",
    "           patches.Patch(color='r', label = 'Non-target (standard)')]\n",
    "\n",
    "# Finalize plot and set a high DPI for a crisp, hi-res figure\n",
    "plt.xlabel('Time (msec)');\n",
    "plt.ylabel('Amplitude (A/D Units)');\n",
    "plt.legend(handles=legend_, loc=\"upper right\");\n",
    "plt.title('Event Related Potentials at channel %s' % chan);\n",
    "fig.set_dpi(216);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the windowed means within erp_start and erp_end\n",
    "num_points = 5; # we will divide our window into num_points means\n",
    "\n",
    "# Define a simple windowed means function\n",
    "def wm(x, start, end, num_points):\n",
    "    num_trials = x.shape[0] # assumes first dem is numb observations\n",
    "    w = np.round((start+end)/num_points).astype(int)\n",
    "    y = np.zeros((num_points, x.shape[-1], num_trials)) # assumes num chans as last dimension\n",
    "    for i in range(0, num_points):\n",
    "        s = start + (w * i)\n",
    "        e = end   + (w * i)\n",
    "        y[i, :, :] = np.mean(x[:, s:e, :], 1).T\n",
    "    return y\n",
    "\n",
    "# Combine into a single train variable. Also create labels\n",
    "X_train    = wm(train_data, erp_s, erp_e, num_points)\n",
    "markers_train = np.vstack((train_labels, train_markers)).T\n",
    "y = train_labels\n",
    "\n",
    "# Now let's compute windowed means of our test data\n",
    "X_test = wm(test_data, erp_s, erp_e, num_points)\n",
    "markers_test = test_markers\n",
    "\n",
    "# Let's print out the shapes of our data\n",
    "print('X_train shape is: ' + str(X_train.shape))\n",
    "print('y shape is......: ' + str(y.shape))\n",
    "print('X_test shape is.: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our X is 3D, we must flatten our data. We will then transpose it for sklearn\n",
    "X_train = X_train.reshape(-1, X_train.shape[-1]).T\n",
    "X_test = X_test.reshape(-1, X_test.shape[-1]).T\n",
    "\n",
    "# Let's print out the new shape\n",
    "print('X_train shape is now: ' + str(X_train.shape))\n",
    "print('X_test  shape is now: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our classifier (this may take a while via JupyterHub)\n",
    "clf_lsqrs = LinearDiscriminantAnalysis(solver = 'lsqr',  shrinkage = 'auto').fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do 5-fold cross validation\n",
    "score_lsqrs = cross_val_score(clf_lsqrs.fit(X_train, y), X_train, y, cv = 5)\n",
    "\n",
    "# We will print out the mean score\n",
    "print(\"solver = lsqr  accuracy: %f\" % np.mean(score_lsqrs))"
   ]
  },
  {
   "source": [
    "# Prototyping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df = get_recording_events(2, 3)\n",
    "df = df[df.song_clip==29].drop(columns=['song_clip','Number','TARGET','time'])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-02\\eeg\\sub-02_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "92 columns passed, passed data had 76 columns",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    689\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 92 columns passed, passed data had 76 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dafff05dad46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFT_Processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-72a8f5eca761>\u001b[0m in \u001b[0;36mFFT_Processing\u001b[1;34m(clip)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquick_bin_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mmeta_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mmetaClip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinalHeaderNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetaClip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    507\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;31m# last ditch effort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 92 columns passed, passed data had 76 columns"
     ]
    }
   ],
   "source": [
    "array = FFT_Processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting EDF parameters from c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data\\sub-02\\eeg\\sub-02_task-run3_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "c:\\Users\\Jack Sheridan\\Documents\\COGS189\\COGS189-final-project\\data_tools.py:16: RuntimeWarning: Invalid date encountered (2014-00-00 00:00:00).\n",
      "  data = mne.io.read_raw_edf(fileName)\n",
      "Index(['time', 'song_clip', 'FP1', 'FP2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T3',\n",
      "       'C3', 'Cz', 'C4', 'T4', 'T5', 'P3', 'Pz', 'P4', 'T6', 'O1', 'O2',\n",
      "       'Number', 'TARGET'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = get_recording_events(2, 3)\n",
    "print(df.columns)"
   ]
  }
 ]
}