{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne # package for reading edf data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  \n",
    "from data_tools import * # i made all t # i made all the functions into a python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Create empty lists to store our data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "test_set = np.random.choice(124, size=24, replace=False)\n",
    "\n",
    "# Going through all 124 trials\n",
    "for subject in range(1,32):\n",
    "    for trial in range(2,6):\n",
    "        df = get_recording_events(subject, trial)\n",
    "        labels = df.groupby('song_clip').head(1).TARGET.to_list() # Should be an array of 10 labels for each of the songs played in this trial\n",
    "        recordings = [df[df.song_clip==x].drop(columns=['song_clip','Number','TARGET','time']) for x in df.song_clip.unique()] \n",
    "        # Going through all 10 playings\n",
    "        for playing in range(0,10):\n",
    "            recording = recordings[playing]\n",
    "            if recording.shape[0] < 16000:\n",
    "                continue\n",
    "            recording = recording.iloc[:16000,:]\n",
    "\n",
    "           \n",
    "            if subject == 31:\n",
    "                test_data.append(recording)\n",
    "                test_labels.append(labels[playing])\n",
    "\n",
    "            else:\n",
    "                train_data.append(recording)\n",
    "                train_labels.append(labels[playing])\n",
    "                    \n",
    "print('Processing completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizer(x):\n",
    "    \"\"\"divides the feature space by perceived arousal level of emotion (high/low)\"\"\"\n",
    "    if x in ['HAPPY', 'FEAR', 'ANGER', 'SURPRISE','HIGH VALENCE', 'HIGH ENERGY','HIGH TENSION']:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 2000 #Averaging band power of 2 sec\n",
    "step_size = 125 #Each 0.125 sec update once\n",
    "sample_rate = 1000 #Sampling rate of 128 Hz\n",
    "#List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'pyeeg' has no attribute 'bin_power'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7e1f716c122d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyeeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Slice raw data over 2 sec, at interval of 0.125 sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyeeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbin_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyeeg' has no attribute 'bin_power'"
     ]
    }
   ],
   "source": [
    "import pyeeg\n",
    "X = train_data[15].Cz[0 : 0 + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "Y = pyeeg.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "X.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_Processing (clip, channel, band, window_size, step_size, sample_rate):\n",
    "    '''\n",
    "    arguments:  string subject\n",
    "                list channel indice\n",
    "                list band\n",
    "                int window size for FFT\n",
    "                int step size for FFT\n",
    "                int sample rate for FFT\n",
    "    return:     void\n",
    "    '''\n",
    "    meta = []\n",
    "\n",
    "    while start + window_size < clip.shape[1]:\n",
    "        meta_array = []\n",
    "        meta_data = [] #meta vector for analysis\n",
    "        for (columnName, columnData) in clip.iteritems():\n",
    "            X = columnData[start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "            Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "            meta_data = meta_data + list(Y[0])\n",
    "\n",
    "        meta_array.append(np.array(meta_data))\n",
    "        meta_array.append(labels)\n",
    "\n",
    "        meta.append(np.array(meta_array))    \n",
    "        start = start + step_size\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "source": [
    "apply a fourier transform to the data in discrete sections so that you can get the average levels of each "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate target and non-target for plotting\n",
    "tar     = train_data[np.where(pd.Series(train_labels).apply(binarizer).to_numpy() == 1)[0], :, :]\n",
    "non_tar = train_data[np.where(pd.Series(train_labels).apply(binarizer).to_numpy() == 0)[0], :, :]\n",
    "\n",
    "print('We have %d target trials' % tar.shape[0])\n",
    "print('We have %d non-target trials' % non_tar.shape[0])\n",
    "\n",
    "# We'll take the average of all trials to create an averaged ERP\n",
    "tar_avg     = np.mean(tar, 0)\n",
    "non_tar_avg = np.mean(non_tar, 0)\n",
    "\n",
    "# Define channel of interest and create an array of time points\n",
    "chan = 'Cz' # let's plot Cz\n",
    "ch = np.where(channels == chan)[0][0]\n",
    "times = np.linspace(epoch_start, epoch_end, train_data.shape[1])\n",
    "\n",
    "# Initialize plot and calculate min and max y value\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 6))\n",
    "min_y = min(np.min(tar_avg), np.min(non_tar_avg))\n",
    "max_y = max(np.max(tar_avg), np.max(non_tar_avg))\n",
    "\n",
    "# Plot x and y axes\n",
    "plt.plot([np.min(times), np.max(times)], [0, 0], color='k');  # x-axis\n",
    "plt.plot([0, 0], [min_y, max_y], color='k');                  # y-axis\n",
    "\n",
    "# Plot our averaged ERPs\n",
    "plt.plot(times, tar_avg[:, ch], 'b', linewidth=4)\n",
    "plt.plot(times, non_tar_avg[:, ch], 'r', linewidth=4)\n",
    "\n",
    "# Highlight the baseline window and window of interest of our ERP\n",
    "baseline = patches.Rectangle([baseline_start, min_y], baseline_end, np.abs(min_y)+max_y, \n",
    "                             color='c', alpha=0.2)\n",
    "erp_win = patches.Rectangle([erp_start, min_y], erp_end-erp_start, np.abs(min_y)+max_y, \n",
    "                             color='lime', alpha=0.3)\n",
    "\n",
    "# Add our baseline and window of interest highlights\n",
    "ax.add_patch(baseline)\n",
    "ax.add_patch(erp_win)\n",
    "\n",
    "# Manually create legends since patches will corrupt default handles\n",
    "legend_ = [patches.Patch(color='b', label = 'Target (oddball)'),\n",
    "           patches.Patch(color='r', label = 'Non-target (standard)')]\n",
    "\n",
    "# Finalize plot and set a high DPI for a crisp, hi-res figure\n",
    "plt.xlabel('Time (msec)');\n",
    "plt.ylabel('Amplitude (A/D Units)');\n",
    "plt.legend(handles=legend_, loc=\"upper right\");\n",
    "plt.title('Event Related Potentials at channel %s' % chan);\n",
    "fig.set_dpi(216);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the windowed means within erp_start and erp_end\n",
    "num_points = 5; # we will divide our window into num_points means\n",
    "\n",
    "# Define a simple windowed means function\n",
    "def wm(x, start, end, num_points):\n",
    "    num_trials = x.shape[0] # assumes first dem is numb observations\n",
    "    w = np.round((start+end)/num_points).astype(int)\n",
    "    y = np.zeros((num_points, x.shape[-1], num_trials)) # assumes num chans as last dimension\n",
    "    for i in range(0, num_points):\n",
    "        s = start + (w * i)\n",
    "        e = end   + (w * i)\n",
    "        y[i, :, :] = np.mean(x[:, s:e, :], 1).T\n",
    "    return y\n",
    "\n",
    "# Combine into a single train variable. Also create labels\n",
    "X_train    = wm(train_data, erp_s, erp_e, num_points)\n",
    "markers_train = np.vstack((train_labels, train_markers)).T\n",
    "y = train_labels\n",
    "\n",
    "# Now let's compute windowed means of our test data\n",
    "X_test = wm(test_data, erp_s, erp_e, num_points)\n",
    "markers_test = test_markers\n",
    "\n",
    "# Let's print out the shapes of our data\n",
    "print('X_train shape is: ' + str(X_train.shape))\n",
    "print('y shape is......: ' + str(y.shape))\n",
    "print('X_test shape is.: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our X is 3D, we must flatten our data. We will then transpose it for sklearn\n",
    "X_train = X_train.reshape(-1, X_train.shape[-1]).T\n",
    "X_test = X_test.reshape(-1, X_test.shape[-1]).T\n",
    "\n",
    "# Let's print out the new shape\n",
    "print('X_train shape is now: ' + str(X_train.shape))\n",
    "print('X_test  shape is now: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our classifier (this may take a while via JupyterHub)\n",
    "clf_lsqrs = LinearDiscriminantAnalysis(solver = 'lsqr',  shrinkage = 'auto').fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do 5-fold cross validation\n",
    "score_lsqrs = cross_val_score(clf_lsqrs.fit(X_train, y), X_train, y, cv = 5)\n",
    "\n",
    "# We will print out the mean score\n",
    "print(\"solver = lsqr  accuracy: %f\" % np.mean(score_lsqrs))"
   ]
  }
 ]
}